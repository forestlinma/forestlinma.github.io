<html xmlns:v="urn:schemas-microsoft-com:vml" xmlns:o="urn:schemas-microsoft-com:office:office" xmlns:w="urn:schemas-microsoft-com:office:word" xmlns:x="urn:schemas-microsoft-com:office:excel" xmlns:m="http://schemas.microsoft.com/office/2004/12/omml" xmlns:st1="urn:schemas-microsoft-com:office:smarttags" xmlns="http://www.w3.org/TR/REC-html40">  <head> <meta http-equiv=Content-Type content="text/html; charset=windows-1252"> <meta name=ProgId content=Word.Document> <meta name=Generator content="Microsoft Word 12"> <meta name=Originator content="Microsoft Word 12">
<link rel="shortcut icon" href="welcome_files/lma.ico">
<title>Lin Ma</title>

<!--
.STYLE1 {font-family: Verdana, Geneva, Arial, Helvetica, sans-serif}
body {
	margin-left: 40px;
	margin-right: 40px;
	margin-bottom: 40px;
}
.STYLE3 {font-size: 12px}
body,td,th {
	font-family: Verdana, Geneva, Arial, Helvetica, sans-serif;
	font-size: 12px;
}
-->
</style>
<style type="text/css">
<!--
.STYLE1 {font-family: Verdana, Geneva, Arial, Helvetica, sans-serif}
.STYLE2 {font-size: 12px}
.STYLE3 {font-size: 10px}
.STYLE4 {font-size: 12.0pt}
.STYLE5 {font-size: 12px; font-weight: bold; }
-->
</style>
</head>
<body lang="EN-US" link="blue" vlink="blue" style="tab-interval:.5in"><o:smarttagtype namespaceuri="urn:schemas-microsoft-com:office:smarttags" name="place">
<o:smarttagtype namespaceuri="urn:schemas-microsoft-com:office:smarttags" name="PlaceName">
<o:smarttagtype namespaceuri="urn:schemas-microsoft-com:office:smarttags" name="PlaceType">
<o:smarttagtype namespaceuri="urn:schemas-microsoft-com:office:smarttags" name="PersonName">
<!--[if gte mso 9]><xml>
 <o:DocumentProperties>
  <o:Author>Polytechnic University</o:Author>
  <o:Template>Normal</o:Template>
  <o:LastAuthor> </o:LastAuthor>
  <o:Revision>162</o:Revision>
  <o:TotalTime>430</o:TotalTime>
  <o:Created>2002-09-10T20:18:00Z</o:Created>
  <o:LastSaved>2011-01-06T21:50:00Z</o:LastSaved>
  <o:Pages>3</o:Pages>
  <o:Words>2431</o:Words>
  <o:Characters>13862</o:Characters>
  <o:Company>Polytechnic University</o:Company>
  <o:Lines>115</o:Lines>
  <o:Paragraphs>32</o:Paragraphs>
  <o:CharactersWithSpaces>16261</o:CharactersWithSpaces>
  <o:Version>12.00</o:Version>
 </o:DocumentProperties>
</xml><![endif]-->
<!--[if gte mso 9]><xml>
 <w:WordDocument>
  <w:Zoom>BestFit</w:Zoom>
  <w:SpellingState>Clean</w:SpellingState>
  <w:GrammarState>Clean</w:GrammarState>
  <w:TrackMoves>false</w:TrackMoves>
  <w:TrackFormatting/>
  <w:HyphenationZone>21</w:HyphenationZone>
  <w:ValidateAgainstSchemas/>
  <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid>
  <w:IgnoreMixedContent>false</w:IgnoreMixedContent>
  <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText>
  <w:DoNotPromoteQF/>
  <w:LidThemeOther>EN-US</w:LidThemeOther>
  <w:LidThemeAsian>ZH-CN</w:LidThemeAsian>
  <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript>
  <w:Compatibility>
   <w:BreakWrappedTables/>
   <w:SnapToGridInCell/>
   <w:ApplyBreakingRules/>
   <w:WrapTextWithPunct/>
   <w:UseAsianBreakRules/>
   <w:DontGrowAutofit/>
   <w:SplitPgBreakAndParaMark/>
   <w:DontVertAlignCellWithSp/>
   <w:DontBreakConstrainedForcedTables/>
   <w:DontVertAlignInTxbx/>
   <w:Word11KerningPairs/>
   <w:CachedColBalance/>
  </w:Compatibility>
  <w:BrowserLevel>MicrosoftInternetExplorer4</w:BrowserLevel>
  <m:mathPr>
   <m:mathFont m:val="Cambria Math"/>
   <m:brkBin m:val="before"/>
   <m:brkBinSub m:val="&#45;-"/>
   <m:smallFrac m:val="off"/>
   <m:dispDef/>
   <m:lMargin m:val="0"/>
   <m:rMargin m:val="0"/>
   <m:defJc m:val="centerGroup"/>
   <m:wrapIndent m:val="1440"/>
   <m:intLim m:val="subSup"/>
   <m:naryLim m:val="undOvr"/>
  </m:mathPr></w:WordDocument>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <w:LatentStyles DefLockedState="false" DefUnhideWhenUsed="false"
  DefSemiHidden="false" DefQFormat="false" LatentStyleCount="267">
  <w:LsdException Locked="false" QFormat="true" Name="Normal"/>
  <w:LsdException Locked="false" QFormat="true" Name="heading 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   QFormat="true" Name="heading 2"/>
  <w:LsdException Locked="false" QFormat="true" Name="heading 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   QFormat="true" Name="heading 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   QFormat="true" Name="heading 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   QFormat="true" Name="heading 6"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   QFormat="true" Name="heading 7"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   QFormat="true" Name="heading 8"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   QFormat="true" Name="heading 9"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   QFormat="true" Name="caption"/>
  <w:LsdException Locked="false" QFormat="true" Name="Title"/>
  <w:LsdException Locked="false" Priority="1" Name="Default Paragraph Font"/>
  <w:LsdException Locked="false" QFormat="true" Name="Subtitle"/>
  <w:LsdException Locked="false" QFormat="true" Name="Strong"/>
  <w:LsdException Locked="false" QFormat="true" Name="Emphasis"/>
  <w:LsdException Locked="false" Priority="99" Name="Plain Text"/>
  <w:LsdException Locked="false" Priority="99" Name="No List"/>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true"
   Name="Placeholder Text"/>
  <w:LsdException Locked="false" Priority="1" QFormat="true" Name="No Spacing"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 1"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 1"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 1"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 1"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 1"/>
  <w:LsdException Locked="false" Priority="99" SemiHidden="true" Name="Revision"/>
  <w:LsdException Locked="false" Priority="34" QFormat="true"
   Name="List Paragraph"/>
  <w:LsdException Locked="false" Priority="29" QFormat="true" Name="Quote"/>
  <w:LsdException Locked="false" Priority="30" QFormat="true"
   Name="Intense Quote"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 1"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 1"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 1"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 1"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 1"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 1"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 2"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 2"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 2"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 2"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 2"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 2"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 2"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 2"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 2"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 2"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 2"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 3"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 3"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 3"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 3"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 3"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 3"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 3"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 3"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 3"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 3"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 3"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 4"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 4"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 4"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 4"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 4"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 4"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 4"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 4"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 4"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 4"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 4"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 5"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 5"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 5"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 5"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 5"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 5"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 5"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 5"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 5"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 5"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 5"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 6"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 6"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 6"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 6"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 6"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 6"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 6"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 6"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 6"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 6"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 6"/>
  <w:LsdException Locked="false" Priority="19" QFormat="true"
   Name="Subtle Emphasis"/>
  <w:LsdException Locked="false" Priority="21" QFormat="true"
   Name="Intense Emphasis"/>
  <w:LsdException Locked="false" Priority="31" QFormat="true"
   Name="Subtle Reference"/>
  <w:LsdException Locked="false" Priority="32" QFormat="true"
   Name="Intense Reference"/>
  <w:LsdException Locked="false" Priority="33" QFormat="true" Name="Book Title"/>
  <w:LsdException Locked="false" Priority="37" SemiHidden="true"
   UnhideWhenUsed="true" Name="Bibliography"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="TOC Heading"/>
 </w:LatentStyles>
</xml><![endif]--><!--[if gte mso 10]>
<style>
 /* Style Definitions */
 table.MsoNormalTable
	{mso-style-name:"Table Normal";
	mso-tstyle-rowband-size:0;
	mso-tstyle-colband-size:0;
	mso-style-noshow:yes;
	mso-style-priority:99;
	mso-style-qformat:yes;
	mso-style-parent:"";
	mso-padding-alt:0in 5.4pt 0in 5.4pt;
	mso-para-margin:0in;
	mso-para-margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:10.0pt;
	font-family:"Times New Roman","serif";}
table.NormaleTabelle
	{mso-style-name:"Normale Tabelle";
	mso-tstyle-rowband-size:0;
	mso-tstyle-colband-size:0;
	mso-style-noshow:yes;
	mso-style-unhide:no;
	mso-style-parent:"";
	mso-padding-alt:0in 5.4pt 0in 5.4pt;
	mso-para-margin:0in;
	mso-para-margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:10.0pt;
	font-family:"Times New Roman","serif";}
</style>
<![endif]-->




<div class="WordSection1 STYLE1 STYLE1">
  <h1 style="margin-right:48.0pt;text-indent:.5in"><img border="0" width="246" height="320" src="welcome_files/linma.png" align="left" v:shapes="Picture_x0020_2"><span style="font-size:16pt">Lin Ma 
  <o:p></o:p>
  </span><span class="STYLE2">Researcher</span></h1>
  <p class="STYLE2" style="margin-right:24.0pt;text-indent:.5in">Meituan</p>
  <p class="STYLE2" style="margin-right:24.0pt;text-indent:.5in">Beijing, China </p>
  <p class="STYLE2" style="margin-right:24.0pt; text-indent:.5in; margin-bottom: 0in;"><span class="STYLE2">
  <o:p><br>
    &nbsp;</o:p>
    </span></p>
<p class="STYLE2" style="margin-right:24.0pt; text-indent:.5in; margin-bottom: 0in;">&nbsp;</p>
<p class="MsoNormal STYLE3 STYLE2" style="margin-right:60.0pt; text-indent:.5in; margin-bottom: 0in;">&nbsp;</p>
<p align="left" class="STYLE2" style="margin-top:0in;margin-right:0in;
margin-bottom:0in;margin-left:1.0in;margin-bottom:.0001pt;text-align:right;
text-indent:.5in">&nbsp;</p>
<p align="left" class="STYLE2" style="margin-top:0in;margin-right:0in;
margin-bottom:0in;margin-left:1.0in;margin-bottom:.0001pt;text-align:right;
text-indent:.5in"><strong>Address:</strong> 2F, Block E, Wangjing International Research Park</p>
<p align="left" class="STYLE2" style="margin-top:0in;margin-right:0in;
margin-bottom:0in;margin-left:1.0in;margin-bottom:.0001pt;text-align:right;
text-indent:.5in">No. 6, Wangjing East Road, </p>
<p align="left" class="STYLE2" style="margin-top:0in;margin-right:0in;
margin-bottom:0in;margin-left:1.0in;margin-bottom:.0001pt;text-align:right;
text-indent:.5in">Chaoyang District, Beijing, China
  <o:p></o:p>
</p>
<p align="right" class="STYLE2" style="margin-right:0pt;text-align:right"><strong><span lang="FR" style="mso-ansi-language:FR">Email: </span></strong><span lang="FR" style="mso-ansi-language:FR"><a href="mailto:forest.linma@gmail.com">forest.linma@gmail.com</a></span> </p>
<p align="right" class="STYLE2" style="margin-right:0pt;text-align:right"><a href="mailto:lma@ee.cuhk.edu.hk">forest.linma@outlook.com<span lang="FR" style="mso-ansi-language:
FR"></span></a></p>
<p align="right" class="STYLE2" style="margin-right:0pt;text-align:right"><a href="mailto:forest.linma@gmail.com"></a><span class="STYLE2" style="mso-ansi-language:FR" lang="FR"><strong>Homepage:</strong>  <a href="http://forestlinma.com">http://forestlinma.com</a></span><span lang="FR" style="mso-ansi-language:FR">
    <o:p></o:p>
</span></p>
<div class="MsoNormal" align="center" style="text-align:center">

<hr size="2" width="100%" align="right">
</div>

<div class="MsoNormal" align="center" style="text-align:center"></div>
<h3 class="MsoNormal">N<span class="STYLE2">EWS</span></h3>
<table class="i_table_entier" style="margin-bottom: 0in">
  <tbody>
  	<!--
    <tr class="pub_tr_2">
      <td colspan="2" align="left"><span class="STYLE2">A  few </span><span class="STYLE5">internship postions</span><span class="STYLE2"> are available. Please contact me if your are interested.</span> </td>
    </tr>
	-->
    <tr class="pub_tr_2">
      <td align="left" class="STYLE2">Aug. 3, 2022 </td>
      <td align="left" class="STYLE2">One papers was accepted to <strong>TOMM</strong>.</td>
    </tr>
    <tr class="pub_tr_2">
      <td align="left" class="STYLE2">Jul. 4, 2022 </td>
      <td align="left" class="STYLE2">Three papers were accepted to <strong>ECCV</strong> 2022.</td>
    </tr>
    <tr class="pub_tr_2">
      <td align="left" class="STYLE2">Jun. 30, 2022 </td>
      <td align="left" class="STYLE2">Two papers were accepted to <strong>ACM MM</strong> 2022.</td>
    </tr>
    <tr class="pub_tr_2">
      <td align="left" class="STYLE2">Jun. 11, 2022 </td>
      <td align="left" class="STYLE2">Our team won the 4th place at the <strong>SoccerNet 2022 Action Spotting</strong> Challenge.</td>
    </tr>
    <tr class="pub_tr_2">
      <td align="left" class="STYLE2">Jun. 9, 2022 </td>
      <td align="left" class="STYLE2">Our team won the 3rd place at the <strong>SoccerNet 2022 Re-Identification</strong> Challenge.</td>
    </tr>
    <tr class="pub_tr_2">
      <td align="left" class="STYLE2">Jun. 2, 2022 </td>
      <td align="left" class="STYLE2">One paper was accepted to <strong>KBS</strong>.</td>
    </tr>
    <tr class="pub_tr_2">
      <td align="left" class="STYLE2">Apr. 15, 2022 </td>
      <td align="left" class="STYLE2">One paper was accepted to <strong>IJCV</strong>.</td>
    </tr>
    <tr class="pub_tr_2">
      <td align="left" class="STYLE2">Feb. 2, 2022 </td>
      <td align="left" class="STYLE2">One paper was accepted to <strong>TMM</strong>.</td>
    </tr>
    <tr class="pub_tr_2">
      <td align="left" class="STYLE2">Jan. 4, 2022 </td>
      <td align="left" class="STYLE2">One paper was accepted to <strong>TMM</strong>.</td>
    </tr>
    <tr class="pub_tr_2">
      <td align="left" class="STYLE2">Dec. 1, 2021 </td>
      <td align="left" class="STYLE2">Two papers were accepted to <strong>AAAI</strong> 2022.</td>
    </tr>
    <tr class="pub_tr_2">
      <td align="left" class="STYLE2">Nov. 24, 2021 </td>
      <td align="left" class="STYLE2">One paper was accepted to <strong>TPAMI</strong>.</td>
    </tr>
    <tr class="pub_tr_2">
      <td align="left" class="STYLE2">Oct. 11, 2021 </td>
      <td align="left" class="STYLE2">Our team <a href="https://arxiv.org/abs/2110.00549">MTVACV</a> won the 2nd place and jury Prize at the <a href="https://vipriors.github.io/challenges/">Visual Inductive Priors for Data-Efficient Computer Vision 2021 Re-Identification Challenge</a>.</td>
    </tr>
    <tr class="pub_tr_2">
      <td align="left" class="STYLE2">Jul. 18, 2021 </td>
      <td align="left" class="STYLE2">One paper was accepted to <strong>TCSVT</strong>.</td>
    </tr>
    <tr class="pub_tr_2">
      <td align="left" class="STYLE2">Jul. 2, 2021 </td>
      <td align="left" class="STYLE2">Two papers were accepted to <strong>ACM MM</strong> 2021.</td>
    </tr>
	  <tr class="pub_tr_2">
      <td align="left" class="STYLE2">Apr. 27, 2021 </td>
      <td align="left" class="STYLE2">One paper was accepted to <strong>ICMR</strong> 2021.</td>
    </tr>
    <tr class="pub_tr_2">
      <td align="left" class="STYLE2">Apr. 23, 2021 </td>
      <td align="left" class="STYLE2">One paper was accepted to <strong>TPAMI</strong>.</td>
    </tr>
    <tr class="pub_tr_2">
      <td align="left" class="STYLE2">Apr. 9, 2021 </td>
      <td align="left" class="STYLE2">The workshop "<strong>LargeFineFoodAI: Large-Scale Fine-Grained Food Analysis</strong>" will be held in conjunction with <strong>ICCV</strong> 2021. [<a href="https://foodai-workshop.meituan.com/foodai2021.html#index">Workshop Homepage</a>] </td>
    </tr>
    <tr class="pub_tr_2">
      <td align="left" class="STYLE2">Feb. 28, 2021 </td>
      <td align="left" class="STYLE2">One paper was accepted to <strong>CVPR</strong> 2021.</td>
    </tr>
    <tr class="pub_tr_2">
      <td align="left" class="STYLE2">Feb. 28, 2021 </td>
      <td align="left" class="STYLE2">One paper was accepted to <strong>TMM</strong>.</td>
    </tr>
    <tr class="pub_tr_2">
      <td align="left" class="STYLE2">Dec. 4, 2020 </td>
      <td align="left" class="STYLE2">One paper was accepted to <strong>AAAI</strong> 2021.</td>
    </tr>
    <tr class="pub_tr_2">
      <td align="left" class="STYLE2">Nov. 2, 2020 </td>
      <td align="left" class="STYLE2">One paper was accepted to <strong>TPAMI</strong>.</td>
    </tr>
    <tr class="pub_tr_2">
      <td align="left" class="STYLE2">Nov. 2, 2020 </td>
      <td align="left" class="STYLE2">One paper was accepted to <strong>TIP</strong>.</td>
    </tr>
    <tr class="pub_tr_2">
      <td align="left" class="STYLE2">Oct. 27, 2020 </td>
      <td align="left" class="STYLE2">One paper was accepted to <strong>TCSVT</strong>.</td>
    </tr>
    <tr class="pub_tr_2">
      <td align="left" class="STYLE2">Sept. 10, 2020 </td>
      <td align="left" class="STYLE2">One paper was accepted to <strong>TMM</strong>.</td>
    </tr>
    <tr class="pub_tr_2">
      <td align="left" class="STYLE2">Sept. 1, 2020 </td>
      <td align="left" class="STYLE2">One paper was accepted to <strong>TIP</strong>.</td>
    </tr>
    <tr class="pub_tr_2">
      <td align="left" class="STYLE2">Aug. 8, 2020 </td>
      <td align="left" class="STYLE2">I am invited as a member of Senior Program Committe (SPC) for <strong>IJCAI</strong> 2021.</td>
    </tr>
    <tr class="pub_tr_2">
      <td align="left" class="STYLE2">Aug. 6, 2020 </td>
      <td align="left" class="STYLE2">One paper was accepted to <strong>TMM</strong>.</td>
    </tr>
	  <tr class="pub_tr_2">
      <td align="left" class="STYLE2">Aug. 5, 2020 </td>
      <td align="left" class="STYLE2">One paper was accepted to <strong>PR</strong>.</td>
    </tr>
    <tr class="pub_tr_2">
      <td align="left" class="STYLE2">Jul. 26, 2020 </td>
      <td align="left" class="STYLE2">Three papers were accepted to <strong>ACM MM</strong> 2020.</td>
    </tr>
    <tr class="pub_tr_2">
      <td align="left" class="STYLE2">Jul. 2, 2020 </td>
      <td align="left" class="STYLE2">Three papers were accepted to <strong>ECCV</strong> 2020.</td>
    </tr>
    <tr class="pub_tr_2">
      <td align="left" class="STYLE2">Jun. 28, 2020 </td>
      <td align="left" class="STYLE2">One paper was accepted to <strong>TNNLS</strong>.</td>
    </tr>
    <tr class="pub_tr_2">
      <td align="left" class="STYLE2">Apr. 1, 2020 </td>
      <td align="left" class="STYLE2">One paper was accepted to <strong>TCSVT</strong>.</td>
    </tr>
    </tr>
    <tr class="pub_tr_2">
      <td align="left" class="STYLE2">Feb. 24, 2020 </td>
      <td align="left" class="STYLE2">Three papers were accepted to <strong>CVPR</strong> 2020, with one Oral and two Posters.</td>
    </tr>
    <tr class="pub_tr_2">
      <td align="left" class="STYLE2">Jan. 22, 2020 </td>
      <td align="left" class="STYLE2">One paper was accepted to <strong>ICRA</strong> 2020.</td>
    </tr>
    <tr class="pub_tr_2">
      <td align="left" class="STYLE2">Nov. 11, 2019 </td>
      <td align="left" class="STYLE2">Three papers were accepted to <strong>AAAI</strong> 2020.</td>
    </tr>
    <tr class="pub_tr_2">
      <td align="left" class="STYLE2">Oct. 23, 2019 </td>
      <td align="left" class="STYLE2">I am invited as a member of Senior Program Committe (SPC) for <strong>IJCAI</strong> 2020.</td>
    </tr>
    <tr class="pub_tr_2">
      <td align="left" class="STYLE2">Sept. 4, 2019 </td>
      <td align="left" class="STYLE2">Two papers were accepted to <strong>NeurIPS</strong> 2019.</td>
    </tr>
    <tr class="pub_tr_2">
      <td align="left" class="STYLE2">Aug. 5, 2019 </td>
      <td align="left" class="STYLE2">I am invited as a member of Senior Program Committe (SPC) for <strong>AAAI</strong> 2020.</td>
    </tr>
    <tr class="pub_tr_2">
      <td align="left" class="STYLE2">Jul. 23, 2019 </td>
      <td align="left" class="STYLE2">Two papers were accepted to <strong>ICCV</strong> 2019.</td>
    </tr>
    <tr class="pub_tr_2">
      <td align="left" class="STYLE2">Jul. 1, 2019 </td>
      <td align="left" class="STYLE2">One paper was accepted to <strong>ACMM MM</strong> 2019.</td>
    </tr>
    <tr class="pub_tr_2">
      <td align="left" class="STYLE2">Jun. 19, 2019 </td>
      <td align="left" class="STYLE2">Our paper entitled as "<strong>Image Deformation Meta-Network for One-Shot Learning</strong>" is selected as one of the best paper finalists (50 out of the 1294 accepted papers in <strong>CVPR</strong> 2019).</td>
    </tr>
    <tr class="pub_tr_2">
      <td align="left" class="STYLE2">May 21, 2019 </td>
      <td align="left" class="STYLE2">One paper was accepted to <strong>TPAMI</strong>.</td>
    </tr>
    <tr class="pub_tr_2">
      <td align="left" class="STYLE2">May 13, 2019 </td>
      <td align="left" class="STYLE2">One paper was accepted to <strong>ACL</strong> 2019.</td>
    </tr>
    <tr class="pub_tr_2">
      <td align="left" class="STYLE2">May 9, 2019 </td>
      <td align="left" class="STYLE2">Two papers were accepted to <strong>IJCAI</strong> 2019.</td>
    </tr>
    <tr class="pub_tr_2">
      <td align="left" class="STYLE2">May 4, 2019 </td>
      <td align="left" class="STYLE2">One paper was accepted to <strong>TCSVT</strong>.</td>
    </tr>
    <tr class="pub_tr_2">
      <td align="left" class="STYLE2">Mar. 28, 2019 </td>
      <td align="left" class="STYLE2">One paper was accepted to <strong>TIP</strong>.</td>
    </tr>
    <tr class="pub_tr_2">
      <td align="left" class="STYLE2">Feb. 25, 2019 </td>
      <td align="left" class="STYLE2">Five papers were accepted to <strong>CVPR</strong> 2019, with two Orals and three Posters.</td>
    </tr>
    <tr class="pub_tr_2">
      <td align="left" class="STYLE2">Nov. 1, 2018 </td>
      <td align="left" class="STYLE2">Three papers were accepted to <strong>AAAI</strong> 2019. </td>
    </tr> 
    <tr class="pub_tr_2">
      <td align="left" class="STYLE2">Sept. 20, 2018 </td>
      <td align="left" class="STYLE2">One paper was accepted to <strong>TIP</strong>. </td>
    </tr>  
    <tr class="pub_tr_2">
      <td align="left" class="STYLE2">Sept. 9, 2018 </td>
      <td align="left" class="STYLE2">Our Team <a href="https://static.googleusercontent.com/media/research.google.com/zh-CN//youtube8m/workshop2018/p_c04.pdf">Y8TM-T</a> won the <strong>fourth (4/312)</strong> place  in <a href="https://research.google.com/youtube8m/workshop2018/index.html">the 2nd Workshop on YouTube-8M Large-Scale Video Understanding</a>. </td>
    </tr>  
    <tr class="pub_tr_2">
      <td align="left" class="STYLE2">Sept. 5, 2018 </td>
      <td align="left" class="STYLE2">Two papers were accepted to <strong>NeurIPS</strong> 2018. </td>
    </tr>  
    <tr class="pub_tr_2">
      <td align="left" class="STYLE2">Aug. 14, 2018 </td>
      <td align="left" class="STYLE2">One paper was accepted to <strong>TIP</strong>. </td>
    </tr>
    <tr class="pub_tr_2">
      <td align="left" class="STYLE2">Aug. 10, 2018 </td>
      <td align="left" class="STYLE2">One paper was accepted to <strong>EMNLP</strong> 2018. </td>
    </tr>
    <tr class="pub_tr_2">
      <td align="left" class="STYLE2">Jul. 3, 2018 </td>
      <td align="left" class="STYLE2">Four papers were accepted to <strong>ECCV</strong> 2018. </td>
    </tr>
    <tr class="pub_tr_2">
      <td align="left" class="STYLE2">Jun. 25, 2018 </td>
      <td align="left" class="STYLE2">One paper was accepted to <strong>TCSVT</strong>. </td>
    </tr>
    <tr class="pub_tr_2">
      <td align="left" class="STYLE2">May 24, 2018 </td>
      <td align="left" class="STYLE2">I am invited as a member of Senior Program Committe (SPC) for <strong>AAAI</strong> 2019.</td>
    </tr>
    <tr class="pub_tr_2">
      <td align="left" class="STYLE2">May 16, 2018 </td>
      <td align="left" class="STYLE2">One paper was accepted to <strong>TIP</strong>. </td>
    </tr>
    <tr class="pub_tr_2">
      <td align="left" class="STYLE2">May 11, 2018 </td>
      <td align="left" class="STYLE2">One paper was accepted to <strong>ICML</strong> 2018. </td>
    </tr>
    <tr class="pub_tr_2">
      <td width="128" align="left" class="STYLE2">Apr. 20, 2018 </td>
      <td width="1073" align="left" class="STYLE2">Two papers were accepted to <strong>IJCAI</strong> 2018. </td>
    </tr>
    <tr class="pub_tr_2">
      <td align="left" class="STYLE2">Feb. 19, 2018 </td>
      <td align="left" class="STYLE2">Five papers were accepted to <strong>CVPR</strong> 2018, with one Spotlight and four Posters. </td>
    </tr>
    <tr class="pub_tr_2">
      <td align="left" class="STYLE2">Feb. 8, 2018 </td>
      <td align="left" class="STYLE2">One paper was accepted to The Web Conference (original <strong>WWW</strong>), The Big Web Track, 2018. </td>
    </tr>
  </tbody>
</table>
<div class="MsoNormal" align="center" style="text-align:center">
  <hr size="2" width="100%" align="center">
</div>
<div class="MsoNormal" align="center" style="text-align:center"></div>
<h3 class="MsoNormal">B<span class="STYLE2">IOGRAPHY</span></h3>
<div align="justify" class="STYLE2">
  <p>Lin Ma is now a Researcher with Meituan, Beijing, China. His current research interests lie in the areas of  deep learning and multimodal learning, specifically for image and language. His Ph.D. research topics are  image/video processing and quality tuning. Previously, 
  he was a Principal Researcher with Tencent AI Lab, Shenzhen, China from Sept. 2016 to Jun. 2020. He was a Researcher with Huawei Noah's Ark Lab, Hong Kong from Aug. 2013 to Sept. 2016. He was a Visiting Student with the School of Computer Engineering, Nanyang Technological University (NTU), from Jul. 2011 to Sept. 2011. He was a Research Assistant with the Department of Electronic Engineering, CUHK, from Nov. 2008 to Jul. 2009.   He was a Research Intern in Microsoft Research Asia from Oct. 2007 to Mar. 2008. He received his Ph.D. degree in Department of Electronic Engineering at the Chinese University of Hong Kong (CUHK) in 2013. He received the B. E., and M. E. degrees from Harbin Institute of Technology, Harbin, China, in 2006 and 2008, respectively, both in computer science. He was a finalist to HKIS young scientist award in engineering science in 2012. He was awarded the Microsoft Research Asia fellowship in 2011. He got the best paper award in Pacific-Rim Conference on Multimedia (PCM) 2008. </p>
  </div>
<div class="MsoNormal" align="center" style="text-align:center">
  <table class="i_table_entier">
    <tbody>
      <tr class="pub_tr_2">
        <td width="341" class="STYLE2"><img src="welcome_files/btn_in_20x15.png" width="20" height="15"><a href="http://hk.linkedin.com/pub/lin-ma/35/b10/268">View Lin Ma's LinkedIn Profile</a> </td>
        <td width="296" class="STYLE2"><img src="welcome_files/google.png" width="15" height="15"> <a href="http://scholar.google.com/citations?user=DAn1pA4AAAAJ&hl=en">View Lin Ma's Google Scholar Citations</a> </td>
      </tr>
    </tbody>
  </table>
  <hr size="2" width="100%" align="center">
</div>
<div class="MsoNormal" align="center" style="text-align:center"></div>
<h3>E<span class="STYLE2">XPERIENCE</span></h3>
<table class="i_table_entier" style="margin-bottom: 0in">
  <tbody>
    <tr class="pub_tr_2">
      <td align="left" class="STYLE2">Jun. 2020 - Present </td>
      <td align="left" class="STYLE2">Researcher, Meituan, Beijing, China </td>
    </tr>
    <tr class="pub_tr_2">
      <td align="left" class="STYLE2">Dec. 2017 - Jun. 2020 </td>
      <td align="left" class="STYLE2">Principal Researcher, Tencent AI Lab, Shenzhen, China </td>
    </tr>
    <tr class="pub_tr_2">
      <td align="left" class="STYLE2">Sept. 2016 - Nov. 2017 </td>
      <td align="left" class="STYLE2">Senior Researcher, Tencent AI Lab, Shenzhen, China </td>
    </tr>
    <tr class="pub_tr_2">
      <td align="left" class="STYLE2">Aug. 2013 - Sept. 2016 </td>
      <td align="left" class="STYLE2">Researcher, Huawei Noah's Ark Lab, Hong Kong, China</td>
    </tr>
    <tr class="pub_tr_2">
      <td width="198" align="left" class="STYLE2">Jul. 2011 - Sept. 2011 </td>
      <td align="left" class="STYLE2">Visiting Student, School of Computer Engineering, Nanyang Technological University (NTU), Singapore </td>
    </tr>
    <tr class="pub_tr_2">
      <td align="left" class="STYLE2">Nov. 2008 - Jul. 2009 </td>
      <td align="left" class="STYLE2">Research Assistant, Department of Electronic Engineering, The Chinese University of Hong Kong (CUHK), Hong Kong, China </td>
    </tr>
    <tr class="pub_tr_1">
      <td align="left" class="STYLE2">Oct. 2007 - Mar. 2008 </td>
      <td align="left" class="STYLE2">Research Intern, Internet Media Group, Microsoft Research Asia (MSRA), Beijing, China </td>
    </tr>
  </tbody>
</table>
<div class="MsoNormal" align="center" style="text-align:center">
  <hr size="2" width="100%" align="center">
</div>
<h3 class="MsoNormal">P<span class="STYLE2">UBLICATIONS</span></h3>
<h3><span class="STYLE4">P</span><span class="STYLE2">REPRINT</span><span class="STYLE2"><u><span style="font-size:12.0pt">
<o:p></o:p>
</span></u></span></h3>
<table border="0" cellpadding="5" cellspacing="0">
  <tbody>
    <tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify"><strong>Video Temporal Relationship Mining for Data-Efficient Person Re-identification</strong><br>
        Siyu Chen, Dengjie Li, Lishuai Gao, Fan Liang, Wei Zhang, and <strong>Lin Ma</strong><br>
        [<a href="https://arxiv.org/abs/2110.00549">arXiv Link</a>] </div></td>
    </tr>
    <tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify"><strong>STH: Spatio-Temporal Hybrid Convolution for Efficient Action Recognition</strong><br>
        Xu Li, Jingwen Wang, <strong>Lin Ma</strong>, Kaihao Zhang, Fengzong Lian, Zhanhui Kang, and Jinjun Wang<br>
        [<a href="https://arxiv.org/abs/2003.08042">arXiv Link</a>] </div></td>
    </tr>
    <tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify"><strong>Weakly-Supervised Multi-Level Attentional Reconstruction Network for Grounding Textual Queries in Videos</strong><br>
        Yijun Song, Jingwen Wang, <strong>Lin Ma</strong>, Zhou Yu, and Jun Yu<br>
        [<a href="https://arxiv.org/abs/2003.07048">arXiv Link</a>] </div></td>
    </tr>
    <tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify"><strong>Look Closer to Ground Better: Weakly-Supervised Temporal Grounding of Sentence in Video</strong><br>
        Zhenfang Chen, <strong>Lin Ma</strong>, Wenhan Luo, Peng Tang, and Kwan-Yee K. Wong<br>
        [<a href="https://arxiv.org/abs/2001.09308">arXiv Link</a>] </div></td>
    </tr>
    <tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify"><strong>LaFIn: Generative Landmark Guided Face Inpainting</strong><br>
        Yang Yang, Xiaojie Guo, Jiayi Ma, <strong>Lin Ma</strong>, and Haibing Ling<br>
        [<a href="https://arxiv.org/abs/1911.11394">arXiv Link</a>] </div></td>
    </tr>
    <tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify"><strong>EDIT: Exemplar-Domain Aware Image-to-Image Translation</strong><br>
        Yuanbin Fu, Jiayi Ma, <strong>Lin Ma</strong>, and Xiaojie Guo<br>
        [<a href="https://arxiv.org/abs/1911.10520">arXiv Link</a>] </div></td>
    </tr>
    <tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify"><strong>PFLD: A Practical Facial Landmark Detector</strong><br>
        Xiaojie Guo, Siyuan Li, Jinke Yu, Jiawang Zhang, JIayi Ma, <strong>Lin Ma</strong>, Wei Liu, and Haibing Ling<br>
        [<a href="hhttps://arxiv.org/abs/1902.10859">arXiv Link</a>] </div></td>
    </tr>
    <tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify"><strong>Real-Time Referring Expression Comprehension by Single-Stage Grounding Network</strong><br>
        Xinpeng Chen, <strong>Lin Ma</strong>, Jingyuan Chen, Zequn Jie, Wei Liu, and Jiebo Luo<br>
        [<a href="https://arxiv.org/abs/1812.03426">arXiv Link</a>] </div></td>
    </tr>
    <tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"> <div align="justify"><strong>Non-local NetVLAD Encoding for Video Classification</strong><br>
        Yongyi Tang, Xing Zhang, Jingwen Wang, Shaoxiang Chen, <strong>Lin Ma</strong>, and Yu-Gang Jiang<br>
        [<a href="https://arxiv.org/abs/1810.00207">arXiv Link</a>] </div></td>
    </tr>
  </tbody>
</table>
<div class="MsoNormal" align="center" style="text-align:center">
  <hr size="2" width="100%" align="center">
</div>
<h3><b style="mso-bidi-font-weight:
normal"><span style="font-size:12.0pt">C<span class="STYLE2">ONFERENCE</span> P<span class="STYLE2">APERS
        <o:p></o:p>
</span></span>
    <span class="STYLE2">
    <o:p></o:p>
    </span></b><span class="STYLE2" style="mso-fareast-font-family:&quot;Times New Roman&quot;">
    <o:p>  </o:p>
    </span></h3>
<table border="0" cellpadding="5" cellspacing="0"> 
<tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><p align="justify"><strong>PromptDet: Expand Your Detector Vocabulary with Uncurated Images</strong><br>
Chengjian Feng, Yujie Zhong, Zequn Jie, Xiangxiang Chu, Haibing Ren, Xiaolin Wei, Weidi Xie, and <strong>Lin Ma</strong><br>
European Conference on Computer Vision (<strong>ECCV</strong>), 2020. <br>
[<a href="https://arxiv.org/abs/2203.16513" target="_blank">arXiv Link</a>][<a href="https://fcjian.github.io/promptdet" target="_blank">Project Homepage</a>][<a href="https://github.com/fcjian/PromptDet" target="_blank">Source Code</a>]
</p>      </td>
  </tr>
<tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><p align="justify"><strong>MORE: Multi-Order RElation Mining for Dense Captioning in 3D Scenes</strong><br>
Yang Jiao, Shaoxiang Chen, Zequn Jie, Jingjing Chen, <strong>Lin Ma</strong>, and Yu-Gang Jiang<br>
European Conference on Computer Vision (<strong>ECCV</strong>), 2020. <br>
[<a href="https://arxiv.org/abs/2203.05203" target="_blank">arXiv Link</a>][<a href="https://github.com/SxJyJay/MORE" target="_blank">Source Code</a>]
</p>      </td>
  </tr>
<tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><p align="justify"><strong>ReAct: Temporal Action Detection with Relational Action Queries</strong><br>
Dingfeng Shi, Yujie Zhong, Qiong Cao, Jing Zhang, <strong>Lin Ma</strong>, Jia Li, and Dacheng Tao<br>
European Conference on Computer Vision (<strong>ECCV</strong>), 2020. <br>
[<a href="https://arxiv.org/abs/2207.07097" target="_blank">arXiv Link</a>][<a href="https://github.com/sssste/React" target="_blank">Source Code</a>]
</p>      </td>
  </tr>
   <tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><p align="justify"><strong>Cycle-Interactive Generative Adversarial Network for Robust Unsupervised Low-Light Enhancement</strong><br>
Zhangkai Ni, Wenhan Yang, Hanli Wang, Shiqi Wang, <strong>Lin Ma</strong>, and Sam Kwong<br>
The 30th ACM International Conference on Multimedia (<strong>ACM MM</strong>), 2022. <br>
[<a href="https://arxiv.org/abs/2207.00965" target="_blank">arXiv Link</a>][<a href="https://eezkni.github.io/publications/CIGAN.html" target="_blank">Project Homepage</a>]
</p>      </td>
  </tr>
   <tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><p align="justify"><strong>Chunk-aware Alignment and Lexical Constraint for Visual Entailment with Natural Language Explanations</strong><br>
Qian Yang, Yunxin Li, Baotian Hu, <strong>Lin Ma</strong>, Yuxin Ding, and Min Zhang<br>
The 30th ACM International Conference on Multimedia (<strong>ACM MM</strong>), 2022. <br>
[<a href="https://arxiv.org/abs/2207.11401" target="_blank">arXiv Link</a>]
</p>      </td>
  </tr>
   <tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><p align="justify"><strong>Explore Inter-Contrast Between Videos via Composition for Weakly Supervised Temporal Sentence Grounding</strong><br>
Jiaming Chen, Weixin Luo, Wei Zhang, and <strong>Lin Ma</strong><br>
The Thirty-sixth AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>), 2022. <br>
[<a href="https://www.aaai.org/AAAI22Papers/AAAI-2108.ChenJ.pdf" target="_blank">Full Text</a>]
</p>      </td>
  </tr>
   <tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><p align="justify"><strong>Visual Consensus Modeling for Video-Text Retrieval</strong><br>
Shuqiang Cao, Bairui Wang, Wei Zhang, and <strong>Lin Ma</strong><br>
The Thirty-sixth AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>), 2022. <br>
[<a href="https://www.aaai.org/AAAI22Papers/AAAI-12427.CaoS.pdf" target="_blank">Full Text</a>]
</p>      </td>
  </tr>
   <tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><p align="justify"><strong>Two-stage Visual Cues Enhancement Network for Referring Image Segmentation</strong><br>
Yang Jiao, Zequn Jie, Weixin Luo, Jingjing Chen, Yu-Gang Jiang, Xiaolin Wei, and <strong>Lin Ma</strong><br>
The 29th ACM International Conference on Multimedia (<strong>ACM MM</strong>), 2021. <br>
[<a href="https://arxiv.org/abs/2110.04435" target="_blank">arXiv Link</a>]
</p>      </td>
  </tr>
   <tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><p align="justify"><strong>Cross-modality Discrepant Interaction Network for RGB-D Salient Object Detection</strong><br>
Chen Zhang, Runmin Cong, Qinwei Lin, <strong>Lin Ma</strong>, Feng Li, Yao Zhao, and Sam Kwong<br>
The 29th ACM International Conference on Multimedia (<strong>ACM MM</strong>), 2021. <br>
[<a href="https://arxiv.org/abs/2108.01971" target="_blank">arXiv Link</a>]
</p>      </td>
</p>      </td>
  </tr>
   <tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><p align="justify"><strong>Relation-aware Instance Refinement for Weakly Supervised Visual Grounding</strong><br>
Yongfei Liu, Bo Wan, <strong>Lin Ma</strong>, and Xuming He<br>
IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2021. <br>
[<a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_Relation-aware_Instance_Refinement_for_Weakly_Supervised_Visual_Grounding_CVPR_2021_paper.pdf" target="_blank">Full Text</a>][<a href="https://github.com/youngfly11/ReIR-WeaklyGrounding.pytorch" target="_blank">Source Code</a>]
</p>      </td>
</p>      </td>
  </tr>
  <tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><p align="justify"><strong>Neural Symbolic Representation Learning for Image Captioning</strong><br>
Xiaomei Wang, <strong>Lin Ma</strong>, Yanwei Fu, and Xiangyang Xue<br>
ACM International Conference on Multimedia Retrieval (<strong>ICMR</strong>), 2021. <br>
[<a href="
https://dl.acm.org/doi/abs/10.1145/3460426.3463637" target="_blank">arXiv Link</a>]
</p>      </td>
  </tr>
   <tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><p align="justify"><strong>Similarity Reasoning and Filtration for Image-Text Matching</strong><br>
Haiwen Diao, Ying Zhang, <strong>Lin Ma</strong>, and Huchuan Lu<br>
The Thirty-fifth AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>), 2021. <br>
[<a href="https://github.com/Paranioar/SGRAF" target="_blank">Source Code</a>]
</p>      </td>
  </tr>
  <tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><p align="justify"><strong>Controllable Video Captioning with an Exemplar Sentence</strong><br>
Yitian Yuan, <strong>Lin Ma</strong>, Jingwen Wang, and Wenwu Zhu<br>
The 28th ACM International Conference on Multimedia (<strong>ACM MM</strong>), 2020. <br>
</p>      </td>
  </tr>
  <tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><p align="justify"><strong>Unpaired Image Enhancement with Quality-Attention Generative Adversarial Network</strong><br>
Zhangkai Ni, Wenhan Yang, Shiqi Wang, <strong>Lin Ma</strong>, and Sam Kwong<br>
The 28th ACM International Conference on Multimedia (<strong>ACM MM</strong>), 2020. <br>
</p>      </td>
  </tr>
  <tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><p align="justify"><strong>Every Moment Matters: Detail-Aware Networks to Bring a Blurry Image Alive</strong><br>
Kaihao Zhang, Wenhan Luo, Bjorn Stenger, Wenqi Ren, <strong>Lin Ma</strong>, and Hongdong Li<br>
The 28th ACM International Conference on Multimedia (<strong>ACM MM</strong>), 2020. <br>
</p>      </td>
  </tr>
 <tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><p align="justify"><strong>Context-Gated Convolution</strong><br>
Xudong Lin, <strong>Lin Ma</strong>, Wei Liu, and Shih-Fu Chang<br>
European Conference on Computer Vision (<strong>ECCV</strong>), 2020. <br>
[<a href="https://arxiv.org/abs/1910.05577" target="_blank">arXiv Link</a>]
</p>      </td>
  </tr>
<tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><p align="justify"><strong>Consensus-Aware Visual-Semantic Embedding for Image-Text Matching</strong><br>
Haoran Wang, Ying Zhang, Zhong Ji, Yanwei Pang, and <strong>Lin Ma</strong><br>
European Conference on Computer Vision (<strong>ECCV</strong>), 2020. <br>
[<a href="https://arxiv.org/abs/2007.08883" target="_blank">arXiv Link</a>][<a href="https://github.com/BruceW91/CVSE" target="_blank">Source Code</a>]
</p>      </td>
  </tr>
<tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><p align="justify"><strong>Beyond Monocular Deraining: Stereo Image Deraining via Semantic Understanding</strong><br>
Kaihao Zhang, Wenhan Luo, Wenqi Ren, Jingwen Wang, Fang Zhao, <strong>Lin Ma</strong>, and Hongdong Li<br>
European Conference on Computer Vision (<strong>ECCV</strong>), 2020. <br>
</p>      </td>
  </tr>
<tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><p align="justify"><strong>Cops-Ref: A new Dataset and Task on Compositional Referring Expression Comprehension</strong><br>
Zhenfang Chen, Peng Wang, <strong>Lin Ma</strong>, Kwan-Yee Wong, and Qi Wu<br>
IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2020. <br>
[<a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Chen_Cops-Ref_A_New_Dataset_and_Task_on_Compositional_Referring_Expression_CVPR_2020_paper.pdf" target="_blank">Full Text</a>][<a href="https://openaccess.thecvf.com/content_CVPR_2020/supplemental/Chen_Cops-Ref_A_New_CVPR_2020_supplemental.pdf" target="_blank">Supplementary Material</a>]
</p>      </td>
  </tr>
  <tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><p align="justify"><strong>Deblurring by Realistic Blurring</strong><br>
Kaihao Zhang, Wenhan Luo, Yiran Zhong, <strong>Lin Ma</strong>, Bjorn Stenger, Wei Liu, and Hongdong Li<br>
IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2020. <br>
[<a href="hhttps://openaccess.thecvf.com/content_CVPR_2020/papers/Zhang_Deblurring_by_Realistic_Blurring_CVPR_2020_paper.pdf" target="_blank">Full Text</a>]
</p>      </td>
  </tr>
  <tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><p align="justify"><strong>Fine-grained Image-to-Image Transformation towards Visual Recognition</strong><br>
Wei Xiong, Yutong He, Yixuan Zhang, Wenhan Luo, <strong>Lin Ma</strong>, and Jiebo Luo<br>
IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2020. <br>
[<a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Xiong_Fine-Grained_Image-to-Image_Transformation_Towards_Visual_Recognition_CVPR_2020_paper.pdf">Full Text</a>][<a href="https://openaccess.thecvf.com/content_CVPR_2020/supplemental/Xiong_Fine-Grained_Image-to-Image_Transformation_CVPR_2020_supplemental.pdf" target="_blank">Supplementary Material</a>][<a href="https://wxiong.me/finegrain/" target="_blank">Project Homepage</a>]
</p>      </td>
  </tr>
	<tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><p align="justify"><strong>Temporally Grounding Language Queries in Videos by Contextual Boundary-aware Prediction</strong><br>
Jingwen Wang, <strong>Lin Ma</strong>, and Wenhao Jiang<br>
The Thirty-fourth AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>), 2020. <br>
[<a href="https://aaai.org/Papers/AAAI/2020GB/AAAI-WangJ.3705.pdf" target="_blank">Full Text</a>][<a href="https://github.com/JaywongWang/CBP" target="_blank">Source Code</a>]
</p>      </td>
  </tr>
  <tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><p align="justify"><strong>Recurrent Nested Model for Sequence Generation</strong><br>
Wenhao Jiang, <strong>Lin Ma</strong>, and Wei Lu<br>
The Thirty-fourth AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>), 2020. <br>
[<a href="https://aaai.org/Papers/AAAI/2020GB/AAAI-JiangW.%203711.pdf" target="_blank">Full Text</a>]
</p>      </td>
  </tr>
  <tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><p align="justify"><strong>Feature Deformation Meta-Networks in Image Captioning of Novel Objects</strong><br>
Tingjia Cao, Ke Han, Xiaomei Wang, <strong>Lin Ma</strong>, Yanwei Fu, Yu-Gang Jiang, and Xiangyang Xue<br>
The Thirty-fourth AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>), 2020. <br>
[<a href="https://aaai.org/Papers/AAAI/2020GB/AAAI-CaoT.4566.pdf" target="_blank">Full Text</a>]
</p>      </td>
  </tr>
  <tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><p align="justify"><strong>Grasp for Stacking via Deep Reinforcement Learning</strong><br>
Junhao Zhang, Wei Zhang, Ran Song, <strong>Lin Ma</strong>, and Yibin Li<br>
International Conference on Robotics and Automation (<strong>ICRA</strong>), 2020.
</p>      </td>
  </tr>
  <tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><p align="justify"><strong>Semantic Conditioned Dynamtic Modulation for Temporal Sentence Grounding in Videos</strong><br>
Yitian Yuan, <strong>Lin Ma</strong>, Jingwen Wang, Wei Liu, and Wenwu Zhu<br>
The Thirty-third Annual Conference on Neural Information Processing Systems (<strong>NeurIPS</strong>), 2019. <br>
[<a href="https://papers.nips.cc/paper/8344-semantic-conditioned-dynamic-modulation-for-temporal-sentence-grounding-in-videos.pdf" target="_blank">Full Text</a>][<a href="https://github.com/yytzsy/SCDM" target="_blank">Source Code</a>]
</p>      </td>
  </tr>
	<tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
  <td height="30" class="STYLE2"><p align="justify"><strong>Exploiting Local and Global Structure for Point Cloud Semantic Segmentation with Contextual Point Representation</strong><br>
Xu Wang, Jingming He, and <strong>Lin Ma</strong><br>
The Thirty-third Annual Conference on Neural Information Processing Systems (<strong>NeurIPS</strong>), 2019.<br>
[<a href="https://papers.nips.cc/paper/8706-exploiting-local-and-global-structure-for-point-cloud-semantic-segmentation-with-contextual-point-representations.pdf">Full Text</a>][<a href="https://github.com/fly519/ELGS">Source Code</a>] 
</p>      </td>
  </tr>
	<tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><p align="justify"><strong>Controllable Video Captioning with POS Sequence Guidance Based on Gated Fusion Network</strong><br>
Bairui Wang, <strong>Lin Ma</strong>, Wei Zhang, Wenhao Jiang, Jingwen Wang, and Wei Liu<br>
International Conference on Computer Vision (<strong>ICCV</strong>), 2019. <br>
[<a href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Wang_Controllable_Video_Captioning_With_POS_Sequence_Guidance_Based_on_Gated_ICCV_2019_paper.pdf">Full Text</a>][<a href="https://arxiv.org/pdf/1908.10072.pdf">arXiv Link</a>][<a href="https://github.com/vsislab/Controllable_XGating">Source Code</a>] 
</p>      </td>
  </tr>
  <tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><p align="justify"><strong>Liquid Warping GAN: A Unified Framework for Human Motion Imitation, Appearance Transfer and Novel View Synthesis</strong><br>
Wen Liu, Zhixin Piao, Jie Min, Wenhan Luo, <strong>Lin Ma</strong>, Shenghua Gao<br>
International Conference on Computer Vision (<strong>ICCV</strong>), 2019. <br>
[<a href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Liu_Liquid_Warping_GAN_A_Unified_Framework_for_Human_Motion_Imitation_ICCV_2019_paper.pdf">Full Text</a>][<a href="https://arxiv.org/pdf/1909.12224.pdf">arXiv Link</a>][<a href="https://svip-lab.github.io/project/impersonator.html">Project Homepage</a>][<a href="https://github.com/svip-lab/impersonator">Source Code</a>]
</p>      </td>
  </tr>
	  <tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><p align="justify"><strong>Sentence Specified Dynamic Video Thumbnail Generation</strong><br>
Yitian Yuan, <strong>Lin Ma</strong>, and Wenwu Zhu<br>
The 27th ACM International Conference on Multimedia (<strong>ACM MM</strong>), 2019.<br>
[<a href="https://arxiv.org/pdf/1908.04052.pdf">arXiv Link</a>][<a href="https://github.com/yytzsy/GTP">Source Code</a>]
</p>      </td>
  </tr>
	  <tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><p align="justify"><strong>Weakly-Supervised Spatio-Temporally Grounding Natural Sentence in Video</strong><br>
Zhenfang Chen, <strong>Lin Ma</strong>, Wenhan Luo, and Kwan-Yee K. Wong<br>
The 57th Annual Meeting of the Association for Computational Linguistics (<strong>ACL</strong>), 2019.<br>
[<a href="https://www.aclweb.org/anthology/P19-1183">Full Text</a>][<a href="https://arxiv.org/abs/1906.02549">arXiv Link</a>][<a href="https://github.com/JeffCHEN2017/WSSTG.git">Source Code</a>]  
</p>      </td>
  </tr>
	  <tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><p align="justify"><strong>Hallucinating Optical Flow Features for Video Classification</strong><br>
Yongyi Tang, <strong>Lin Ma</strong>, and Lianqiang Zhou<br>
International Joint Conference on Artificial Intelligence (<strong>IJCAI</strong>), 2019.<br>
[<a href="https://arxiv.org/abs/1905.11799">arXiv Link</a>][<a href="https://github.com/YongyiTang92/MoNet-Features">Source Code</a>] 
</p>      </td>
  </tr>
	  <tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><p align="justify"><strong>Position Focused Attention Network For Image-Text Matching</strong><br>
Yaxiong Wang, Hao Yang, Xueming Qian, <strong>Lin Ma</strong>, Jing Lu, Biao Li, and Xin Fan<br>
International Joint Conference on Artificial Intelligence (<strong>IJCAI</strong>), 2019.<br>
[<a href="https://arxiv.org/pdf/1907.09748.pdf">arXiv Link</a>][<a href="https://github.com/HaoYang0123/Position-Focused-Attention-Network">Source Code</a>] 
</p>      </td>
  </tr>
	  <tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><p align="justify"><strong>Unsupervised Image Captioning</strong><br>
Yang Feng, <strong>Lin Ma</strong>, Wei Liu, and Jiebo Luo<br>
IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2019.<br>
[<a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Feng_Unsupervised_Image_Captioning_CVPR_2019_paper.pdf">Full Text</a>][<a href="https://arxiv.org/abs/1811.10787">arXiv Link</a>][<a href="https://github.com/fengyang0317/unsupervised_captioning">Source Code</a>] 
</p>      </td>
  </tr>
  <tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><p align="justify"><strong>Spatio-temporal Video Re-localization by Warp LSTM</strong><br>
Yang Feng, <strong>Lin Ma</strong>, Wei Liu, and Jiebo Luo<br>
IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2019.<br>
[<a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Feng_Spatio-Temporal_Video_Re-Localization_by_Warp_LSTM_CVPR_2019_paper.pdf">Full Text</a>][<a href="https://arxiv.org/abs/1905.03922">arXiv Link</a>][<a href="https://github.com/fengyang0317/STVR">Source Code</a>]
</p>      </td>
  </tr>
  <tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><p align="justify"><strong>Multi-granularity Generator for Temporal Action Proposal</strong><br>
Yuan Liu, <strong>Lin Ma</strong>, Yifeng Zhang, Wei Liu, and Shih-Fu Chang<br>
IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2019.<br>
[<a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Liu_Multi-Granularity_Generator_for_Temporal_Action_Proposal_CVPR_2019_paper.pdf">Full Text</a>][<a href="https://arxiv.org/abs/1811.11524">arXiv Link</a>] 
</p>      </td>
  </tr>
  <tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><p align="justify"><strong>Learning Joint Gait Representation via Quintuplet Loss Minimization</strong><br>
Kaihao Zhang, Wenhan Luo, <strong>Lin Ma</strong>, Wei Liu, and Hongdong Li<br>
IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2019. (<strong>Oral</strong>)<br>
[<a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Zhang_Learning_Joint_Gait_Representation_via_Quintuplet_Loss_Minimization_CVPR_2019_paper.pdf">Full Text</a>]
</p>      </td>
  </tr>
  <tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><p align="justify"><strong>Image Deformation Meta-Network for One-Shot Learning</strong><br>
Zitian Chen, Yanwei Fu, Yu-Xiong Wang, <strong>Lin Ma</strong>, Wei Liu, and Martial Hebert<br>
IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2019. (<strong>Oral</strong>)<br>
[<a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Chen_Image_Deformation_Meta-Networks_for_One-Shot_Learning_CVPR_2019_paper.pdf">Full Text</a>][<a href="https://github.com/tankche1/IDeMe-Net">Source Code</a>]
</p>      </td>
  </tr>
	  <tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><p align="justify"><strong>Hierarchical Photo-Scene Encoder for Album Storytelling</strong><br>
Bairui Wang, <strong>Lin Ma</strong>, Wei Zhang, Wenhao Jiang, and Feng Zhang<br>
The Thirty-third AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>), 2019. <br>
[<a href="welcome_files/Bairui_Wang_Hierarchical_Photo-Scene_Encoder_AAAI_2019.pdf">Full Text</a>]
</p>      </td>
  </tr> 
	  <tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><p align="justify"><strong>Localizing Natural Language in Videos</strong><br>
Jingyuan Chen, <strong>Lin Ma</strong>, Xinpeng Chen, Zequn Jie, and Jiebo Luo<br>
The Thirty-third AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>), 2019. <br>
[<a href="welcome_files/Jingyuan_Chen_Localizing_Natural_Language_In_Videos_AAAI_2019.pdf">Full Text</a>]
</p>      </td>
  </tr> 
	  <tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><p align="justify"><strong>Cousin Network Guided Sketch Recognition via Latent Attribute Warehouse</strong><br>
Kaihao Zhang, Wenhan Luo, <strong>Lin Ma</strong>, and Hongdong Li<br>
The Thirty-third AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>), 2019. <br>
[<a href="welcome_files/Kaihao_Zhang_Cousin_Network_Guided_Sketch_Recognition_AAAI_2019.pdf">Full Text</a>]
</p>      </td>
  </tr> 
	  <tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><p align="justify"><strong>Deep Non-blind Deconvolution via Generalized Low-rank Approximation</strong><br>
Wenqi Ren, Jiawei Zhang, <strong>Lin Ma</strong>, Jinshan Pan, Xiaochun Cao, Wangmeng Zuo, Wei Liu, and Ming-Hsuan Yang<br>
The Thirty-second Annual Conference on Neural Information Processing Systems (<strong>NeurIPS</strong>), 2018. <br>
[<a href="welcome_files/Wenqi_Ren_Deep_Non-Blind_Deconvolution_NIPS_2018.pdf">Full Text</a>][<a href="https://github.com/rwenqi/NBD-GLRA">Source Code</a>]
</p>      </td>
  </tr> 
    <tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><p align="justify"><strong>Parsimonious Quantile Regression of Asymmetrically Heavy-tailed Financial Return Series</strong><br>
Xing Yan, Weizhong Zhang, <strong>Lin Ma</strong>, Wei Liu, and Qi Wu<br>
The Thirty-second Annual Conference on Neural Information Processing Systems (<strong>NeurIPS</strong>), 2018.<br>
[<a href="welcome_files/Xing_Yan_Parsimonious_Quantile_Regression_NIPS_2018.pdf">Full Text</a>] 
</p>      </td>
  </tr> 
	  <tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><p align="justify"><strong>Temporally Grounding Natural Sentence in Video</strong><br>
Jingyuan Chen, Xinpeng Chen, <strong>Lin Ma</strong>, Zequn Jie, and Tat-Seng Chua<br>
Conference on Empirical Methods in Natural Language Processing (<strong>EMNLP</strong>), 2018. <br>
[<a href="welcome_files/Jingyuan_Chen_Temporally_Grounding_EMNLP_2018.pdf">Full Text</a>][<a href="https://github.com/JaywongWang/TGN" target="_blank">Source Code</a>]</p>      </td> 
</p>      </td>
  </tr> 
	  <tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><p align="justify"><strong>Video Re-localization</strong><br>
Yang Feng, <strong>Lin Ma</strong>, Wei Liu, Tong Zhang, and Jiebo Luo<br>
European Conference on Computer Vision (<strong>ECCV</strong>), 2018. <br>  
[<a href="welcome_files/Yang_Feng_Video_Re-localization_via_ECCV_2018_paper.pdf">Full Text</a>][<a href="https://arxiv.org/abs/1808.01575">arXiv Link</a>][<a href="https://github.com/fengyang0317/video_reloc">Source Code</a>]</p>      </td>
  </tr> 
  <tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><p align="justify"><strong>Recurrent Fusion Network for Image Captioning</strong><br>
Wenhao Jiang, <strong>Lin Ma</strong>, Yu-Gang Jiang, Wei Liu, and Tong Zhang<br>
European Conference on Computer Vision (<strong>ECCV</strong>), 2018.<br> 
[<a href="welcome_files/Wenhao_Jiang_Recurrent_Fusion_Network_ECCV_2018_paper.pdf">Full Text</a>][<a href="https://arxiv.org/abs/1807.09986">arXiv Link</a>][<a href="https://github.com/cswhjiang/Recurrent_Fusion_Network">Source Code</a>]</p>      </td>
  </tr>
  <tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><p align="justify"><strong>Unsupervised Image-to-Image Translation with Stacked Cycle-Consistent Adversarial Networks</strong><br>
Minjun Li, Haozhi Huang, <strong>Lin Ma</strong>, Wei Liu, Tong Zhang, and Yu-Gang Jiang<br>
European Conference on Computer Vision (<strong>ECCV</strong>), 2018. <br>
[<a href="welcome_files/Minjun_Li_Unsupervised_Image-to-Image_Translation_ECCV_2018_paper.pdf">Full Text</a>][<a href="https://arxiv.org/abs/1807.08536">arXiv Link</a>]</p>      </td>
  </tr>
  <tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><p align="justify"><strong>Neural Stereoscopic Image Style Transfer</strong><br>
Xinyu Gong, Haozhi Huang, <strong>Lin Ma</strong>, Fumin Shen, Wei Liu, and Tong Zhang<br>
European Conference on Computer Vision (<strong>ECCV</strong>), 2018.<br>
[<a href="welcome_files/Xinyu_Gong_Neural_Stereoscopic_Image_ECCV_2018_paper.pdf">Full Text</a>][<a href="https://arxiv.org/abs/1802.09985">arXiv Link</a>]</p>      </td>
  </tr>
  <tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><div align="justify"><strong>Safe Element Screening for Submodular Function Minimization</strong><br>
      Weizhong Zhang, Bin Hong, <strong>Lin Ma</strong>, Wei Liu, and Tong Zhang<br>
      International Conference on Machine Learning (<strong>ICML</strong>), 2018. <br>
[<a href="welcome_files/weizhongzhang_ICML2018.pdf">Full Text</a>]
			</div></td>
  </tr>
  <tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><p align="justify"><strong>Long-Term Human Motion Prediction by Modeling Motion Context and Enhancing Motion Dynamics</strong><br>
Yongyi Tang, <strong>Lin Ma</strong>, Wei Liu, and Wei-Shi Zheng<br>
International Joint Conference on Artificial Intelligence (<strong>IJCAI</strong>), 2018. <br>
[<a href="welcome_files/Yongyi_Tang_Long-term_Human_Motion_Prediction_via_IJCAI_2018.pdf">Full Text</a>][<a href="https://arxiv.org/abs/1805.02513">arXiv Link</a>]</p>      </td>
  </tr>
  <tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><div align="justify"><strong>Image-level to Pixel-wise Labeling: From Theory to Practice</strong><br>
      Tiezhu Sun, Wei Zhang, Zhijie Wang, <strong>Lin Ma</strong>, and Zequn Jie      <br>
      International Joint Conference on Artificial Intelligence (<strong>IJCAI</strong>), 2018.<br>
[<a href="welcome_files/Tiezhu_Sun_Image-leve_to_Pixel-wise_Labeling_via_IJCAI_2018.pdf">Full Text</a>]</div></td>
  </tr>
  <tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><div align="justify">
      <p><strong>Regularizing RNNs for Caption Generation by Reconstructing The Past with The Present</strong><br>
        Xinpeng Chen, <strong>Lin Ma</strong>, Wenhao Jiang, Jian Yao, and Wei Liu<br>
        IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2018. <br>
[<a href="welcome_files/xinpengchen_CVPR2018.pdf">Full Text</a>][<a href="https://arxiv.org/abs/1803.11439">arXiv Link</a>][<a href="https://github.com/chenxinpeng/ARNet">Source Code</a>]</p>
      </div></td>
  </tr>
  <tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><div align="justify"><strong>Reconstruction Network for Video Captioning</strong><br>
      Bairui Wang, <strong>Lin Ma</strong>, Wei Zhang, and Wei Liu<br>  
      IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2018. <br>
[<a href="welcome_files/bairuiwang_CVPR2018.pdf">Full Text</a>][<a href="https://arxiv.org/abs/1803.11438">arXiv Link</a>]</div></td>
  </tr>
  <tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><div align="justify"><strong>Gated Fusion Network for Single Image Dehazing</strong>        <br>
        Wenqi Ren, <strong>Lin Ma</strong>, Jiawei Zhang, Jinshan Pan, Xiaochun Cao, Wei Liu, and Ming-Hsuan Yang<br>
                IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2018. <br>
[<a href="welcome_files/wenqiren_CVPR2018.pdf">Full Text</a>][<a href="https://arxiv.org/abs/1804.00213">arXiv Link</a>][<a href="https://sites.google.com/site/renwenqi888/research/dehazing/gfn">Project Homepage</a>][<a href="https://github.com/rwenqi/GFN-dehazing">Source Code</a>]</div>
      <div align="justify"></div></td>
  </tr>
  <tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><div align="justify"><strong>Bidirectional Attentive Fusion with Context Gating for Dense Video Captioning</strong>  <br>
      Jingwen Wang, Wenhao Jiang, <strong>Lin Ma</strong>, Wei Liu, and Yong Xu<br>
      IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2018. (<strong>Spotlight</strong>)<br>
[<a href="welcome_files/jingwenwang_CVPR2018.pdf">Full Text</a>][<a href="https://arxiv.org/abs/1804.00100">arXiv Link</a>][<a href="https://github.com/JaywongWang/DenseVideoCaptioning">Source Code</a>]<br>
    </div></td>
  </tr>
  <tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><div align="justify"><strong>Learning to Generate Time-Lapse Videos Using Multi-Stage Dynamic Generative Adversarial Networks</strong><br>
      Wei Xiong, Wenhan Luo, <strong>Lin Ma</strong>, Wei Liu, and Jiebo Luo<br>
      IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2018. <br>
[<a href="welcome_files/weixiong_CVPR2018.pdf">Full Text</a>][<a href="https://arxiv.org/abs/1709.07592">arXiv Link</a>]</div></td>
  </tr>
  <tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><div align="justify"><strong>Fine-grained Video Attractiveness Prediction Using Multimodal Deep Learning on a Large Real-world Dataset</strong><br>
      Xinpeng Chen, Jingyuan Chen, <strong>Lin Ma</strong>, Jian Yao, Wei Liu, Jiebo Luo, and Tong Zhang      <br>
      The Web Conference (original <strong>WWW</strong>), The Big Web Track, 2018.
       <br>
       [<a href="welcome_files/xpchen_WWW_2018.pdf">Ful Text</a>][<a href="https://arxiv.org/abs/1804.01373">arXiv Link</a>]    </div></td>
  </tr>
  <tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><div align="justify"><strong>Learning to Guide Decoding for Image Captioning</strong><br>
      Wenhao Jiang, <strong>Lin Ma</strong>, Xinpeng Chen, Hanwang Zhang, and Wei Liu      <br>
      The Thirty-second AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>), 2018.
       <br>
[<a href="https://arxiv.org/abs/1804.00887">arXiv Link</a>]      <br>
    </div></td>
  </tr>
  <tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><div align="justify"><strong>Real-Time Neural Style Transfer for Videos</strong><br>
      Haozhi Huang, Hao Wang, Wenhan Luo, <strong>Lin Ma</strong>, Wenhao Jiang, Xiaolong Zhu, Zhifeng Li, and Wei Liu<br>
            IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2017. <br>
            [<a href="welcome_files/hzhuang_CVPR_2017.pdf">Full Text</a>] </div></td>
  </tr>
  <tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><div align="jus5ify"><strong>Learning to Answer Questions From Image Using Convolutional Neural Network</strong> <br>
      <strong>Lin Ma</strong>, Zhengdong Lu, and Hang Li      <br>
      The Thirtieth AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>), 2016. <br>
      [<a href="welcome_files/lma_AAAI2016_slides.pptx">Oral Presentation</a>][<a href="welcome_files/lma_AAAI_2016.pdf">Full Text</a>][<a href="http://arxiv.org/abs/1506.00333">arXiv Link</a>][<a href="http://conviqa.noahlab.com.hk/project.html">Project Homepage</a>] </div></td>
  </tr>
  <tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><div align="justify"><strong>Multimodal Convolutional Neural Networks for Matching Image and Sentence</strong><br>
      <strong>Lin Ma</strong>, Zhengdong Lu, Lifeng Shang, and Hang Li      <br>
      International Conference on Computer Vision (<strong>ICCV</strong>), 2015. <br>
      [<a href="welcome_files/ICCV2015_poster.pdf">Poster Presentation</a>][<a href="welcome_files/lma_ICCV_2015.pdf">Full Text</a>][<a href="http://arxiv.org/abs/1504.06063">arXiv Link</a>][<a href="http://mcnn.noahlab.com.hk/project.html">Project Homepage</a>]</div></td>
  </tr>
  <tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><div align="justify"><strong>Screen Content Image Quality Assessment Using Edge Model</strong><br>
      Zhangkai Ni, <strong>Lin Ma</strong>, Huanqiang Zeng, Canhui Cai, and Kai-Kuang Ma      <br>
      International Conference on Image Processing (<strong>ICIP</strong>), 2016. <br>
      [<a href="welcome_files/zkni_icip2016.pdf">Full Text</a>] </div></td>
  </tr>
  <tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><p><strong>Perceptual Image Quality Enhancement for Solar Radio Image</strong><br>
      Long Xu,&nbsp;<strong>Lin Ma</strong>, Zhuo Chen, Xianyou Zeng, and Yihua Yan<br>
International Conference on Quality of Multimedia Experience (<strong>QoMex</strong>)<em>,</em> 2016.<br>
[<a href="http://www.ee.cuhk.edu.hk/~lma/welcome_files/lxu_qomex2016.pdf">Full Text</a>]</p>      </td>
  </tr>
  <tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><strong>Deep Learning Features Inspired Saliency Detection of 3D Images</strong><br>
      Qiudan Zhang, Xu Wang, Jianmin Jiang, and&nbsp;<strong>Lin Ma</strong><br>
      Pacific-Rim Conference on Multimedia (<strong>PCM</strong>), 2016. <br>
      [<a href="http://www.ee.cuhk.edu.hk/~lma/welcome_files/xwang_pcm_2016.pdf">Full Text</a>]</td>
  </tr>
  <tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><strong>Perceptual Quality Improvement for Synthesis Imaging of Chinese Spectral Radiohelograph</strong><br>
      Long Xu,&nbsp;<strong>Lin Ma</strong>, Zhuo Chen, Yihua Yan, and Jinjian Wu<br>
      Pacific-Rim Conference on Multimedia (<strong>PCM</strong>), 2015.<br>
      [<a href="http://www.ee.cuhk.edu.hk/~lma/welcome_files/lxu_pcm2015.pdf">Full Text</a>]</td>
  </tr>
  <tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><strong>A Packet-Layer Model with Content Characteristics for Video Quality Assessment of IPTV</strong><br>
      Qian Zhang,&nbsp;<strong>Lin Ma</strong>, Fan Zhang, and Long Xu<br>
      Pacific-Rim Conference on Multimedia (<strong>PCM</strong>), 2015.<br>
      [<a href="http://www.ee.cuhk.edu.hk/~lma/welcome_files/qzhang_pcm2015.pdf">Full Text</a>]</td>
  </tr>
  <tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><div align="justify">
      <p><strong>Rank Learning Based No-Reference Quality Assessment of Retargeted Images<br>
        Lin Ma</strong>, Long Xu, Yichi Zhang, King Ngi Ngan, Yihua Yan<br>
        IEEE International Conference on Systems, Man, and Cybernetics (<strong>SMC</strong>), 2015.<br>
        [<a href="welcome_files/lma_smc2015.pdf">Full Text</a>] </p>
      </div></td>
  </tr>
  <tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><div align="justify"><strong>Multimodal Learning for Classification of Solar Radio Spectrum</strong><br>
      Zhuo Chen, <strong>Lin Ma</strong>, Long Xu, Yihua Yan<br>
        IEEE International Conference on Systems, Man, and Cybernetics (<strong>SMC</strong>) 2015.<br>
        [<a href="welcome_files/zchen_smc2015.pdf">Full Text</a>] </div></td>
  </tr>
  <tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><div align="justify"><strong>Multi-task Rank Learning for Image Quality Assessment</strong><br>
      Long Xu, Jia Li, Weisi Lin, Yongbing Zhang, <strong>Lin Ma</strong>, Yuming Fang, Yun Zhang, and Yihua Yan<br>
        IEEE International Conference on Acoustics, Speech and Signal Processing (<strong>ICASSP</strong>), 2015.<br>
        [<a href="welcome_files/lxu_icassp2015.pdf">Full Text</a>] </div></td>
  </tr>
  <tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><div align="justify"><strong>How Does the Shape Descriptor  Measure the Perceptual Quality of the Retargeted Image?<br>
      Lin Ma</strong>, Long Xu, Huanqiang  Zeng, King Ngi Ngan, and Chenwei Deng<br>
         IEEE International Conference on Multimedia  and Expo (<strong>ICME</strong>) Workshop on Emerging Multimedia Systems and Applications, 2014.<br>
           [<a href="welcome_files/lma_ICME_2014.pdf">Full Text</a>] </div></td>
  </tr>
  <tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><div align="justify"><strong>Visual Quality Metric for Perceptual Video Coding</strong><br>
      Long Xu, <strong>Lin Ma</strong>, King Ngi Ngan,  Weisi Lin, and Ying Weng<br>
        IEEE Visual Communications and Image Processing (<strong>VCIP</strong>), 2013. <br>
        [<a href="welcome_files/lma_VCIP_2013.pdf">Full Text</a>] </div></td>
  </tr>
  <tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><div align="justify"><strong>Packet-layer Model for Quality Assessment of Encrypted Video in IPTV Services</strong><br>
      Qian Zhang, Fan Zhang, and <strong>Lin Ma</strong><br> 
        Asia Pacific Signal and Information Processing Association Annual Summit and Conference (<strong>APSIPA ASC</strong>), 2013. <br>
        [<a href="welcome_files/lma_APSIPA_ASC_2013.pdf">Full Text</a>] </div></td>
  </tr>
  <tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><div align="justify"><strong>High Quality Image Construction from Multiple Low Quality Copies<br>
      Lin Ma</strong>, Long Xu, Qian Zhang, and King Ngi Ngan<br>
        International Workshop on Multimedia Signal Processing (<strong>MMSP</strong>), 2013.<br>
        [<a href="welcome_files/lma_MMSP_2013.pdf">Full Text</a>] </div></td>
  </tr>
  <tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><div align="justify"><strong>Reduced Reference Video Quality Assessment Based on Spatial HVS Mutual  Masking and Temporal Motion Estimation<br>
      Lin Ma</strong>, King Ngi Ngan, and Long  Xu<br>
        IEEE International Conference on Multimedia and Expo (<strong>ICME</strong>) in Multimedia  for Humanity Theme Track, 2013.<br>
        [<a href="welcome_files/lma_ICME_2013.pdf">Full Text</a>]</div></td>
  </tr>
  <tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><div align="justify"><strong>Overview of Quality Assessment for Visual Signals and Newly Emerged Trends<br>
      Lin Ma</strong>, Chenwei Deng, Weisi Lin, and King Ngi Ngan<br>
        International Symposium on Circuits and Systems (<strong>ISCAS</strong>), 2013.<br>
        [<a href="welcome_files/lma_ISCAS_2013.pdf">Full Text</a>] </div></td>
  </tr>
  <tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><div align="justify"><strong>Video Quality Metric for Consistent Visual Quality Control in Video Coding</strong><br>
      Long Xu, King Ngi Ngan, Songnan Li, and<strong> Lin Ma</strong><br>
        Asia Pacific Signal and Information Processing Association Annual Summit and Conference (<strong>APSIPA ASC</strong>), 2012. <br>
          [<a href="welcome_files/lma_APSIPA_ASC_2012.pdf">Full Text</a>] </div></td>
  </tr>
  <tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><div align="justify"><strong>Study of Subjective and Objective Quality Assessment of Retargeted Images<br>
      Lin Ma</strong>, Weisi Lin, Chenwei Deng, and King Ngi Ngan<br>
        International Symposium on Circuits and Systems (<strong>ISCAS</strong>), 2012.<br>
        [<a href="welcome_files/lma_ISCAS_2012.pdf">Full Text</a>] [<a href="http://ivp.ee.cuhk.edu.hk/projects/demo/retargeting/index.html">Project Homepage</a>] </div></td>
  </tr>
  <tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
    <td height="30" class="STYLE2"><div align="justify"><strong>Reduced-Reference Image Quality Assessment via Intra- and Inter-Subband Statistical Characteristics in Reorganized DCT Domain<br>
      Lin Ma</strong>, Songnan Li, and King Ngi Ngan<br>
        Asia Pacific Signal and Information Processing Association Annual Summit and Conference (<strong>APSIPA ASC</strong>), 2011.<br>
        [<a href="welcome_files/lma_APSIPA_ASC_2011.pdf">Full Text</a>].</div></td>
  </tr>
  <tbody>
  <tr class="pub_tr_2">
    <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify">
        <p><strong>Video Quality Assessment by Decoupling Additive Impairments and Detail losses</strong><br>
          Songnan Li, <strong>Lin Ma</strong>, and King Ngi Ngan<br> 
          International Workshop on Quality of Multimedia Experience(<strong>QoMEX</strong>), 2011.<br>
          <a href="welcome_files/snli_QoMEX_2011.pdf">[Full Text</a>] </p>
        </div></td>
    </tr>
    <tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify"><strong>A Visual Saliency Modulated Just Noticeable Distortion Profile for Image Watermarking</strong><br>
        Yaqing Niu, Matthew Kyan, <strong>Lin Ma</strong>, Azeddine Beghdadi, and Sridhar Krishnan <br>
          European Signal Processing Conference (<strong>EUSIPCO</strong>), 2011. <br> 
          [<a href="welcome_files/yqniu_EUSIPCO_2011.pdf">Full Text</a>] </div></td>
    </tr>
    <tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify"><strong>Motion Trajectory Based Visual Saliency for Video Quality Assessment<br>
        Lin Ma</strong>, Songnan Li, and King Ngi Ngan<br> 
          International Conference on Image Processing  (<strong>ICIP</strong>), 2011. <br>
          [<a href="welcome_files/lma_ICIP_2011.pdf">Full Text</a>] </div></td>
    </tr>
    <tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify" class="STYLE2"><strong>Perceptual Image Compression via Adaptive Block-Based Super-Resolution Directed  Down-Sampling<br>
        Lin Ma</strong>, Songnan Li, and King Ngi Ngan<br>
        International Symposium on Circuits and Systems  (<strong>ISCAS</strong>), 2011.<br>
        [<a href="welcome_files/lma_ISCAS_2011.pdf">Full Text</a>] </div></td>
    </tr>
    <tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify" class="STYLE2">
        <p><strong>Video Quality Assessment Based on Adaptive Block-Size Transform  Just-Noticeable Difference Model<br>
        </strong><strong>Lin Ma</strong>, Fan Zhang, Songnan Li, and King Ngi Ngan<br>
          International Conference on Image Processing  (<strong>ICIP</strong>), 2010. <br>
          [<a href="welcome_files/lma_ICIP_2010.pdf">Full Text</a>] </p>
        </div></td>
    </tr>
    <tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify" class="STYLE2"><strong>Adaptive Block-Size Transform Based Just-Noticeable Difference Profile for  Videos<br>
        Lin Ma</strong>, and King Ngi Ngan<br>
        International Symposium on Circuits and Systems (<strong>ISCAS</strong>), 2010. <br>
        [<a href="welcome_files/lma_ISCAS_2010.pdf">Full Text</a>] </div></td>
    </tr>
    <tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify" class="STYLE2"><strong>Adaptive  Block-Size Transform Based Just-Noticeable Difference Profile for Images<br>
        Lin Ma</strong>, and King Ngi Ngan<br>
        Pacific-Rim Conference on Multimedia (<strong>PCM</strong>),  2009.<br>
        [<a href="welcome_files/lma_PCM_2009.pdf">Full Text</a>] </div></td>
    </tr>
    <tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify" class="STYLE2"><strong>Learning-based Image Restoration for Compressed Image through  Neighboring Embedding<br>
        Lin Ma</strong>, Feng Wu, Debin  Zhao, Wen Gao, and Siwei Ma<br>
         Pacific-Rim Conference on Multimedia (<strong>PCM</strong>), 2008.<br>
        [<a href="welcome_files/lma_PCM_2008.pdf">Full Text</a>] <strong><a href="welcome_files/lma_Best_Pape_Award.jpg">(Best Paper  Award)</a></strong></div></td>
    </tr>
    <tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify" class="STYLE2"><strong>Three-tiered Network Model for Image Hallucination<br>
        Lin Ma</strong>, Yonghua Zhang, Yan Lu,  Feng Wu, and Debin Zhao<br>
        International Conference of Image Processing (<strong>ICIP</strong>), 2008. <br>
         [<a href="welcome_files/lma_ICIP_2008.pdf">Full Text</a>] </div></td>
    </tr>
    <tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify" class="STYLE2"><strong>Temporal Inconsistency Measure for Video  Quality Assessment</strong><br>
        Songnan Li, <strong>Lin  Ma</strong>, Fan Zhang, and King Ngi Ngan<br>
        Picture Coding Symposium (<strong>PCS</strong>), 2010. <br>
        [<a href="welcome_files/lma_PCS_2010.pdf">Full Text</a>] </div></td>
    </tr>
    <tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify" class="STYLE2"><strong>Limitation and Challenges of Image Quality  Measurement</strong><br>
        Fan Zhang, Songnan Li, <strong>Lin Ma</strong>, and King Ngi Ngan<br>
        Visual Communications and Image Processing (<strong>VCIP</strong>), 2010.<br>
        [<a href="welcome_files/lma_VCIP_2010.pdf">Full Text</a>] </div></td>
    </tr>
    <tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify" class="STYLE2"><strong>Universal Steganalysis Based on Statistical Models Using Reorganization of  Block-based DCT Coefficients</strong><br>
        Shaohui Liu, <strong>Lin Ma</strong>, Hongxun Yao, and Debin Zhao<br>
        International Conference on Information Assurance  and Security (<strong>IAS</strong>), 2009. <br>
        [<a href="welcome_files/lma_IAS_2009.pdf">Full Text</a>] </div></td>
    </tr>
  </tbody>
</table>
<div class="MsoNormal" align="center" style="text-align:center">
  <hr size="2" width="100%" align="center">
</div>
<div class="MsoNormal" align="center" style="text-align:center"></div>
<h3><span style="font-size:12.0pt">J<span class="STYLE2">OURNAL</span> P<span class="STYLE2">APER<span class="STYLE4">s</span></span></span><span class="STYLE2"><u><span style="font-size:12.0pt">
  <o:p></o:p>
</span></u></span></h3>
<table border="0" cellpadding="5" cellspacing="0">
  <tbody>
    <tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify"><strong>Beyond Monocular Deraining: Parrallel Stereo Deraining Network via Semantic Prior</strong><br>
        Kaihao Zhang, Wenhan Luo, Yanjiang Yu, Wenqi Ren, Fang Zhao, Changsheng Li, <strong>Lin Ma</strong>, Wei Liu, and Hongdong Li
        <br>
        Internatinal Journal of Computer Vision (<strong>IJCV</strong>). Accepted <br>
        [<a href="https://arxiv.org/abs/2112.01062" target="_blank">arXiv Link</a>]
        </div></td>
    </tr>
    <tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify"><strong>Syntax Customized Video Captioning by Imitating Exemplar Sentences</strong><br>
        Yitian Yuan, <strong>Lin Ma</strong>, and Wenwu Zhu
        <br>
        IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>TPAMI</strong>). Accepted <br>
        [<a href="https://arxiv.org/abs/2112.01062" target="_blank">arXiv Link</a>]
        </div></td>
    </tr>
    <tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify"><strong>Semantic Conditioned Dynamic Modulation for Temporal Sentence Grounding in Videos</strong><br>
        Yitian Yuan, <strong>Lin Ma</strong>, Jingwen Wang, Wei Liu, and Wenwu Zhu
        <br>
        IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>TPAMI</strong>), vol. 44, no. 5, pp. 2725-2741, May 2022. <br>
        </div></td>
    </tr>
    <tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify"><strong>Liquid Warping GAN with Attention: A Unified Framework for Human Image Synthesis</strong><br>
        Wen Liu, Zhixin Piao, Zhi Tu, Wenhan Luo, <strong>Lin Ma</strong>, and Shenghua Gao
        <br>
        IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>TPAMI</strong>). Accepted <br>
        </div></td>
    </tr>
    <tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify"><strong>A Closer Look at Debiased Temporal Sentence Grounding in Videos: Dataset, Metric, and Approach</strong><br>
        Xiaohan Lan, Yitian Yuan, Xin Wang, Long Chen, Zhi Wang, <strong>Lin Ma</strong>, and Wenwu Zhu
        <br>
        ACM Transactions on Multimedia Computing Communications and Applications (<strong>TOMM</strong>). Accepted <br>
        </div></td>
    </tr>
    <tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify"><strong>Weakly Supervised Semantic Segmentation via Progressive Patch Learning</strong><br>
        Jinglong Li, Zequn Jie, Xu Wang, Yu Zhou, Xiaolin Wei, and <strong>Lin Ma</strong>
        <br>
        IEEE Transactions on Multimedia (<strong>TMM</strong>). Accepted <br>
        </div></td>
    </tr>
    <tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify"><strong>Content-aware recommendation via Dynamic Heterogeneous Graph Convolutional Network</strong><br>
        Tingting Liang, <strong>Lin Ma</strong>, Weizhong Zhang, Haoran Xu, Congying Xia, and Yuyu Yin
        <br>
        Knowledge-Based Systems (<strong>KBS</strong>). Accepted <br>
        </div></td>
    </tr>
    <tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify"><strong>Fast and Robust Online Handwritten Chinese Character Recognition with Deep Spatial & Contextual Information Fusion Network</strong><br>
        Yunxin Li, Yunxin Li, Qian Yang, Qingcai Chen, Baotian Hu, Xiaolong Wang, Yuxin Ding, and <strong>Lin Ma</strong>
        <br>
        IEEE Transactions on Multimedia (<strong>TMM</strong>). Accepted <br>
        </div></td>
    </tr>
    <tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify"><strong>CASNet: A Cross-attention Siamese Network for Video Salient Object Detection</strong><br>
        Yuzhu Ji, Haijun Zhang, Zequn Jie, <strong>Lin Ma</strong>, and Jonathan Wu
        <br>
        IEEE Transactions on Neural Networks and Learning Systems (<strong>TNNLS</strong>), vol. 32, no. 6, pp. 2676-2690, Jun. 2021. <br>
        </div></td>
    </tr>
  	<tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify"><strong>Reconstruct and Represent Video Contents for Captioning via Reinforcement Learning</strong><br>
        Wei Zhang, Bairui Wang, <strong>Lin Ma</strong>, and Wei Liu
        <br>
        IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>TPAMI</strong>), vol. 42, no. 12, pp. 3088-3101, Dec. 2020.<br>
        </div></td>
    </tr>
    <tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify"><strong>Disentangled Feature Networks for Facial Portraits Generation</strong><br>
        Kaihao Zhang, Wenhan Luo, <strong>Lin Ma</strong>, Wenqi Ren, and Hongdong Li
        <br>
        IEEE Transactions on Multimedia (<strong>TMM</strong>), vol. 24, pp. 1378-1388, 2022.<br>
        </div></td>
    </tr>
    <tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify"><strong>Progressive Point Cloud Upsampling via Differentiable Rendering</strong><br>
        Pingping Zhang, Xu Wang, <strong>Lin Ma</strong>, Shiqi Wang, Sam Kwong, and Jianmin Jiang
        <br>
        IEEE Transactions on Circuits and Systems for Video Technology (<strong>TCSVT</strong>), vol. 31, no. 12, pp. 4673-4685, Dec. 2021. <br>
        </div></td>
    </tr>
    <tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify"><strong>Coupled Network for Robust Pedestrian Detection with Gated Multi-Layer Feature Extraction and Deformable Occlusion Handling</strong><br>
        Tianrui Liu, Wenhan Luo, <strong>Lin Ma</strong>, Jun-jie Huang, Tania Stathaki, and Tianhong Dai
        <br>
        IEEE Transactions on Image Processing (<strong>TIP</strong>), vol. 30, pp. 754-766, 2021.<br>
        </div></td>
    </tr>
    <tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify"><strong>Pyramid Global Context Network for Image Dehazing</strong><br>
        Dong Zhao, Long Xu, <strong>Lin Ma</strong>, Jia Li, and Yihua Yan
        <br>
        IEEE Transactions on Circuits and Systems for Video Technology (<strong>TCSVT</strong>), vol. 31, no. 8, pp. 3037-3050, Aug. 2021.<br>
        </div></td>
    </tr>
    <tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify"><strong>Towards Unsupervised Deep Image Enhancement with Generative Adversarial Network</strong><br>
        Zhangkai Ni, Wenhan Yang, Shiqi Wang, <strong>Lin Ma</strong>, and Sam Kwong
        <br>IEEE Transactions on Image Processing (<strong>TIP</strong>), vol. 29, pp. 9140-9151, 2020. <br>
        </div></td>
    </tr>
    <tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify"><strong>PFAN++: Bi-Directional Image-Text Retrieval with Position Focused Attention Network</strong><br>
        Yaxiong Wang, Hao Yang, Xiuxiu Bai, Xueming Qian, <strong>Lin Ma</strong>, Jing Lu, Biao Li, and Xin Fan
        <br>
        IEEE Transactions on Multimedia (<strong>TMM</strong>), vol. 23, pp. 3362-3376, Sept. 2021. <br>
        </div></td>
    </tr>
    <tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify"><strong>Multi-Exposure Decomposition-Fusion Model for High Dynamic Range Image Saliency Detection</strong><br>
        Xu Wang, Zhenhao Sun, Qiudan Zhang, Yuming Fang, <strong>Lin Ma</strong>, Shiqi Wang, and Sam Kwong
        <br>
        IEEE Transactions on Circuits and Systems for Video Technology (<strong>TCSVT</strong>), vol. 30, no. 12, pp. 4409-4420, Dec. 2020.<br>
        </div></td>
    </tr>
    <tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify"><strong>Unsupervised Text-to-Image Synthesis</strong><br>
        Yanlong Dong, Ying Zhang, <strong>Lin Ma</strong>, Zhi Wang, and Jiebo Luo
        <br>
        Pattern Recognition (<strong>PR</strong>), vol. 110, 107573, Feb. 2021. <br>
        </div></td>
    </tr>
    <tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify"><strong>Quality Evaluation for Image Retargeting with Instance Semantics</strong><br>
        Leida Li, Yixuan Li, Jinjian Wu, <strong>Lin Ma</strong>, and Yuming Fang
        <br>
        IEEE Transactions on Multimedia (<strong>TMM</strong>), vol. 23, pp. 2757-2769, 2021.<br>
        </div></td>
    </tr>
  	<tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify"><strong>Matching Image and Sentence with Multi-faceted Representations</strong><br>
        <strong>Lin Ma</strong>, Wenhao Jiang, Zequn Jie, Yu-Gang Jiang, and Wei Liu
        <br>
        IEEE Transactions on Circuits and Systems for Video Technology (<strong>TCSVT</strong>), vol. 30, no. 7, pp. 2250-2261, Jul. 2020.  <br>
        </div></td>
    </tr>
  	<tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify"><strong>Low-Light Image Enhancement via a Deep Hybrid Network</strong><br>
        Wenqi Ren, Sifei Liu, <strong>Lin Ma</strong>, Qianqian Xu, Xiangyu Xu, Xiaochun Cao, Junping Du, and Ming-Hsuan Yang
        <br>
        IEEE Transactions on Image Processing (<strong>TIP</strong>), vol. 28, no. 9, pp. 4364-4375, Sept. 2019. <br>
        </div></td>
    </tr>
  	<tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify"><strong>Deep Video Dehazing with Semantic Segmentation</strong><br>
        Wenqi Ren, Jingang Zhang, Xiangyu Xu, <strong>Lin Ma</strong>, Xiaochun Cao, Gaofeng Meng, and Wei Liu
        <br>
        IEEE Transactions on Image Processing (<strong>TIP</strong>), vol. 28, no. 4, pp. 1895-1908, Apr. 2019. <br>
        <a href="welcome_files/Wenqi_Ren_Deep_Video_Dehazing_TIP_2019.pdf">[Full Text</a>]
        </div></td>
    </tr>
  	<tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify"><strong>Bidirectional Image-Sentence Retrieval by Local and Global Deep Matching</strong><br>
        <strong>Lin Ma</strong>, Wenhao Jiang, Zequn Jie, and Xu Wang
        <br>
        Neurocomputing (<strong>NC</strong>), vol. 345, pp. 36-44, Jun. 2019. <br>
     </div></td>
    </tr>
  	<tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify"><strong>Towards Efficient Action Recognition: Principal Backpropagation for Training Two-Stream Networks</strong><br>
        Wenbing Huang, Lijie Fan, Mehrtash Harandi, Chuang Gan, <strong>Lin Ma</strong>, Huaping Liu, and Wei Liu
        <br>
        IEEE Transactions on Image Processing (<strong>TIP</strong>), vol. 28, no. 4, pp. 1773-1782, Apr. 2019. <br>
        <a href="welcome_files/Wenbing_Huang_Towards_Efficient_Action_Recognition_TIP_2019.pdf">[Full Text</a>]
     </div></td>
    </tr>
    <tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify"><strong>Adversarial Spatio-Temporal Learning for Video Deblurring</strong><br>
        Kaihao Zhang, Wenhan Luo, Yiran Zhong, <strong>Lin Ma</strong>, Wei Liu, and Hongdong Li
        <br>
        IEEE Transactions on Image Processing (<strong>TIP</strong>), vol. 28, no. 1, pp. 291-301, Jan. 2019. <br>
        <a href="welcome_files/Kaihao_Zhang_Adversarial_Spatiao-Temporal_Learning_TIP_2018.pdf">[Full Text</a>]</div></td>
    </tr>
  	<tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify"><strong>Deep Intensity Guidance Based Compression Artifacts Reduction for Depth Map</strong><br>
        Xu Wang, Pingping Zhang, Yun Zhang, <strong>Lin Ma</strong>, Sam Kwong, and Jianmin Jiang
        <br>
        Journal of Visual Communication and Image Representation, vol. 57, pp. 234-242, 2018. <br>
        <a href="welcome_files/Xu_Wang_Deep_Intensity_Guidance_JVCI_2018.pdf">[Full Text</a>]
     </div></td>
    </tr>  	
    <tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify"><strong>Screen Content Image Quality Assessment Using Multi-scale Difference of Gaussian</strong><br>
        Ying Fu, Huanqiang Zeng, <strong>Lin Ma</strong>, Zhangkai Ni, Canhui Cai, and Kai-Kuang Ma
        <br>
        IEEE Transactions on Circuits and Systems for Video Technology (<strong>TCSVT</strong>), vol. 28, no. 9, pp. 2428-2432, Sept. 2018.  <br>
        <a href="welcome_files/Ying_Fu_Screen_Image_Quality_Assessment_TCSVT_2018.pdf">[Full Text</a>]</div></td>
    </tr>
    <tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify"><strong>A Gabor Feature-based Quality Assessment Model for the Screen Content Images</strong><br>
        Zhangkai Ni, Huanqiang Zeng, <strong>Lin Ma</strong>,  Junhui Hou, Jing Chen, and Kai-Kuang Ma<br>
        IEEE Transactions on Image Processing (<strong>TIP</strong>), vol. 27, no. 9, pp. 4516-4528, Sept. 2018. <br>
        <a href="welcome_files/zkni_TIP_2018.pdf">[Full Text</a>] [<a href="http://smartviplab.org/pubilcations/GFM.html">Project Homepage</a>] </div></td>
    </tr>
    <tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify"><strong>Image Processing for Synthesis Imaging of Mingantu Spectral Radioheliograph (MUSER)</strong><br>
        Long Xu, Yihua Yan, <strong>Lin Ma</strong>, and Yun Zhang<br>
        Multimedia Tools and Applications (<strong>MTAP</strong>), vol. 77, no. 16, pp. 20937-20954, Aug. 2018. <br> </div></td>
    </tr>
    <tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify"><strong>Reversible Data Hiding for High Dynamic Range Images Using Edge Information</strong><br>
        Xuanyu He, Wei Zhang, Haifeng Zhang, <strong>Lin Ma</strong>, Yibin Li<br>
        Multimedia Tools and Applications (<strong>MTAP</strong>). Accepted <br> </div></td>
    </tr>
    <tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify"><strong>Objective Quality Assessment of Image Retargeting by Incorporating Fidelity Measures and Inconsistency Detection</strong><br>
        Yichi Zhang, King Ngi Ngan, <strong>Lin Ma</strong>,  and Hongliang Li<br>
              IEEE Transactions on Image Processing (<strong>TIP</strong>), vol. 26, no. 12, pp. 5980-5993, Dec. 2017. <br>
                <a href="welcome_files/yczhang_TIP_2017.pdf">[Full Text</a>] </div></td>
    </tr>
    <tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify"><strong>ESIM: Edge Similarity for Screen Content Image Quality Assessment</strong><br>
        Zhangkai Ni, <strong>Lin Ma</strong>, Huanqiang Zeng, Jing Chen, Canhui Cai, and Kai-Kuang Ma<br> 
            IEEE Transactions on Image Processing (<strong>TIP</strong>), vol. 26, no. 10, pp. 4818-4831, Oct. 2017. <br>
            [<a href="welcome_files/lma_TIP2017_SCI.pdf">Full_Text</a>] </div></td>
    </tr>
    <tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;.</td>
      <td height="30" class="STYLE2"><div align="justify"><strong>Multi-task Rank Learning for Image Quality Assessment</strong><br>
        Long Xu, Jia Li, Weisi Lin, Yongbing Zhang, <strong>Lin Ma</strong>, Yuming Fang, and Yihua Yan<br>
              IEEE Transactions on Circuits and Systems for Video Technology (<strong>TCSVT</strong>), vol. 27, no. 9, pp. 1833-1843, Sept. 2017. <br>
                [<a href="welcome_files/lxu_TCSVT_2017.pdf">Full Text</a>]</div></td>
    </tr>
    <tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify"><strong>Quaternion Represenation Based Visual Saliency for Stereoscopic Image Quality Assessment</strong><br>
        Xu Wang, <strong>Lin Ma</strong>, Sam Kwong, and Yu Zhou<br>
              Signal Processing (<strong>SP</strong>), vol. 145, pp. 202-213, Apr. 2018. <br>
                [<a href="welcome_files/xwang_sp_2018.pdf">Full Text</a>]</div></td>
    </tr>
    <tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><strong>The Use of Convolutional Neural Artificail Intellignece Network to Aid the Diagnosis and Classification of Early Esophageal Neoplasia</strong><br>
        Chenzi Zhang, <strong>Lin Ma</strong>, Noriya Uedo, Noriko Matsuura, Parry Tam, and Anthony Y. Teoh<br>
        Gastrointestinal Endoscopy, vol. 85, no. 5S, pp. AB507-AB588, 2017. <br>
        [<a href="welcome_files/czhang_GE2017.pdf">Full Text</a>]. </td>
    </tr>
    <tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify"><strong>Visual Tracking using Global Sparse Coding and Local Convolutional Features</strong><br>
        Xianyou Zeng, Long Xu, <strong>Lin Ma</strong>, Ruizhen Zhao, and Yigang Cen<br>
              Digital Signal Processing (<strong>DSP</strong>), vol. 72,  pp. 115-125, Jan. 2018. <br>
                [<a href="welcome_files/xyzeng_dsp2018.pdf">Full Text</a>] </div></td>
    </tr>
    <tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify"><strong>No-Reference Retargeted Image Quality Assessment Based on Pairwise Rank Learning<br>
        Lin Ma</strong>, Long Xu, Yichi Zhang, Yihua Yan, and King Ngi Ngan<br>
          IEEE Transaction on Multimedia (<strong>TMM</strong>), vol. 18, no. 11, pp. 2228-2237, Nov. 2016. <br>
            [<a href="welcome_files/lma_TMM_2016.pdf">Full Text</a>] </div></td>
    </tr>
    <tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify"> <strong>Just Noticeable Difference Estimation for Screen Content Images</strong><br>
        Shiqi Wang, <strong>Lin Ma</strong>, Yuming Fang, Weisi Lin, Siwei Ma, and Wen Gao<br>
        IEEE Transactions on Image Processing (<strong>TIP</strong>), vol. 25, no. 8, pp. 3838-3851, Aug. 2016. <br>
        [<a href="welcome_files/sqwang_TIP_2016.pdf">Full Text</a>] </div></td>
    </tr>
    <tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify"><strong>Gradient Direction for Screen Content Image Quality Assessment</strong><br>
        Zhangkai Ni, <strong>Lin Ma</strong>, Huanqiang Zeng, Canhui Cai, and Kai-Kuang Ma<br>
          IEEE Signal Processing Letters (<strong>SPL</strong>), vol. 23, no. 10, pp. 1394-1398, Oct. 2016. <br>
            [<a href="welcome_files/zkni_spl_2016.pdf">Full Text</a>] [<a href="http://www.ee.cuhk.edu.hk/~lma/welcome_files/SCI_GSS.html">Project Homepage</a>] [<a href="http://www.ee.cuhk.edu.hk/~lma/welcome_files/SCI_GSS/SCI_GSS.m">Code</a>] </div></td>
    </tr>
    <tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify"><strong>Multimodal Deep Learning for Solar Radio Burst Classification<br>
        Lin Ma</strong>, Zhuo Chen, Long Xu, and Yihua Yan<em><br>
          </em>Pattern Recognition (<strong>PR</strong>), vol. 61, pp. 573-582, Jan. 2017. <br>
          [<a href="welcome_files/lma_PR_2017.pdf">Full Text</a>] </div></td>
    </tr>
    <tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify"><strong>Learning Structure of Stereoscopic Image for No-Reference Quality Assessment with Convolutional Neural Network</strong><br>
        Wei Zhang, Chenfei Qu<strong>, Lin Ma</strong>, Jingwei Guan, and Rui Huang<br>
          Pattern Recognition (<strong>PR</strong>), vol. 59, pp. 176-187, Nov. 2016. <br>
          [<a href="welcome_files/lma_PR_2016.pdf">Full Text</a>] [<a href="http://www.ee.cuhk.edu.hk/~lma/welcome_files/StereoImageQA.html">Project Homepage</a>]</div></td>
    </tr>
    <tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify"><strong>Free-energy Principle Inspired Video Quality Metric and Its Use in Video Coding</strong><br>
        Long Xu,  Weisi Lin, <strong>Lin Ma</strong>, Yongbing Zhang, Yuming Fang, King Ngi Ngan, Songnan Li, and Yihua Yan<br>
          IEEE Transaction on Multimedia (<strong>TMM</strong>), vol. 18, no. 4, pp. 590-602, Apr. 2016. <br>
          [<a href="welcome_files/lxu_TMM_2016.pdf">Full Text</a>]</div></td>
    </tr>
    <tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify"><strong>Reorganized DCT-based Image Representation for Reduced Reference Stereoscopic Image Quality Assessment<br>
        Lin Ma</strong>, Xu Wang, Qiong Liu, and King Ngi Ngan<br>
          Neurocomputing (<strong>NC</strong>), vol. 215, pp. 21-31, Nov. 2016. <br>
          [<a href="welcome_files/lma_NC_2016.pdf">Full Text</a>] </div></td>
    </tr>
    <tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify"><strong>Multimodal Learning For Facial Expression Recognition</strong><br>
        Wei Zhang, Youmei Zhang<strong>, Lin Ma</strong>, Jingwei Guan, and Shijie Gong<br>
          Pattern Recognition (<strong>PR</strong>), vol. 48, no. 10, pp. 3191-3202, Oct. 2015. <br>
          [<a href="welcome_files/lma_PR_2015.pdf">Full Text</a>] [<a href="http://www.vsislab.com/papers/FER/FER.html">Project Homepage</a>]</div></td>
    </tr>
    <tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify"><strong>Imaging and Representation Learning of Solar Radio Spectrums for Classification</strong><br>
        Zhuo Chen<strong>, Lin Ma</strong>, Long Xu, Chengming Tan, and Yihua Yan<br>
          Multimedia Tools and Applications (<strong>MTAP</strong>), vol. 75, no. 5, pp. 2859-2875, Mar. 2016. <br>
            [<a href="welcome_files/lma_MTA_2015.pdf">Full Text</a>]</div></td>
    </tr>
    <tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify"><strong>Reduced-Reference Image Quality Assessment in Reorganized DCT Domain<br>
        Lin Ma</strong>, Songnan Li, and King Ngi Ngan<br>
          Signal Processing: Image Communication (<strong>SPIC</strong>), vol. 28, no. 8, pp. 884-902, Aug. 2013. <br>
          [<a href="welcome_files/lma_SPIC_2013.pdf">Full Text</a>]. </div></td>
    </tr>
    <tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify">
        <div align="justify"><strong>Visual Saliency's Modulatory Effect on Just Noticeable Distortion Profile and Its Application in Image Watermarking</strong><br>
          Yaqing Niu, Matthew Kyan, <strong>Lin Ma</strong>, Azeddine Beghdadi, and Sridhar Krishnan<em><br>
            </em>Signal Processing: Image Communication (<strong>SPIC</strong>), vol. 28, no. 8, pp. 917-928, Aug. 2013. <br>
              [<a href="welcome_files/yaniu_SPIC_2013.pdf">Full Text</a>] </div>
      </div></td>
    </tr>
    <tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><p align="justify"><strong>Consistent Visual  Quality Control in Video Coding</strong><br>
        Long Xu, Songnan Li,  King Ngi Ngan, and <strong>Lin Ma</strong><br>
              IEEE Transactions on Circuits and Systems for Video Technology (<strong>TCSVT</strong>), vol. 23, no. 6, pp. 975-989, Jun. 2013. <br>
            [<a href="welcome_files/lxu_TCSVT_2013.pdf">Full Text</a>] </p></td>
    </tr>
    <tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify"><strong>Recent Advances and Challenges of Visual Signal Quality Assessment<br>
        Lin Ma</strong>, Chenwei Deng, King Ngi Ngan, and Weisi Lin<br>
          China Communications, vol. 10, no. 5, pp. 62-78, 2013. <br>
          [<a href="welcome_files/lma_ChinaCommunications_2013.pdf">Full Text</a>] </div></td>
    </tr>
    <tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify"><strong>Anaglyph Image Generation by Matching Color Appearance Attributes</strong><br>
        Songnan Li, <strong>Lin Ma</strong>, and King Ngi Ngan<br>
Signal Processing: Image Communication (<strong>SPIC</strong>), vol. 28, no. 6, pp. 597-607, Jul. 2013. <br>
[<a href="welcome_files/snli_SPIC.pdf">Full Text</a>] </div></td>
    </tr>
    <tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify"><strong>Image Retargeting Quality Assessment: A Study of Subjective Scores and Objective Metrics<br>
        Lin Ma</strong>, Weisi Lin, Chenwei Deng, and King Ngi Ngan<br>
          IEEE Journal of Selected Topics in Signal Processing (<strong>JSTSP</strong>), vol. 6, no. 6, pp. 626-639, Oct. 2012. <br>
            [<a href="welcome_files/lma_JSTSP.pdf">Full Text </a>] [<a href="http://ivp.ee.cuhk.edu.hk/projects/demo/retargeting/index.html">Project Homepage</a>] . </div></td>
    </tr>
    <tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify"><strong>Reduced-Reference Video Quality Assessment of Compressed Video Sequences<br>
        Lin Ma</strong>, Songnan Li, and King Ngi Ngan<br>
              IEEE Transactions on Circuits and Systems for Video Technology (<strong>TCSVT</strong>), vol. 22, no. 10, pp. 1441-1456, Oct. 2012. <br>
                [<a href="welcome_files/lma_TCSVT_2012.pdf">Full Text</a>] </div></td>
    </tr>
    <tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify"><strong>Full-reference Video Quality Assessment by Decoupling Detail Losses and Additive Impairments</strong><br>
        Songnan Li, <strong>Lin Ma</strong>, and King Ngi Ngan<br>
          IEEE Transactions on Circuits and Systems for Video Technology (<strong>TCSVT</strong>), vol. 22, no. 7, pp. 1100-1112, Jul. 2012.  <br>
            [<a href="welcome_files/snli_TCSVT.pdf">Full Text</a>] </div></td>
    </tr>
    <tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="pub_td_text"><div align="justify"><span class="STYLE2"><strong>Learning-based Image Restoration for Compressed Images<br>
        Lin Ma</strong>, Debin Zhao, and Wen Gao<br>
        Signal Processing: Image Communication (<strong>SPIC</strong>), vol. 27, no. 1, pp. 54-65, Jan. 2012. <br>
        [<a href="welcome_files/lma_SPIC_2012.pdf">Full Text</a>] </span></div></td>
    </tr>
    <tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify" class="STYLE2">
        <p><strong>Image Quality Assessment by Separately Evaluating Detail Losses and Additive Impairments</strong><br>
          Songnan Li, Fan Zhang, <strong>Lin Ma</strong>, and King Ngi Ngan<br>
          IEEE Transaction on Multimedia (<strong>TMM</strong>), vol. 13, no. 5, pp. 935-949, Oct. 2011. <br>
          [<a href="welcome_files/snli_TMM_2011.pdf">Full Text</a>] </p>
        </div></td>
    </tr>
    <tr class="pub_tr_2">
      <td  height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify" class="STYLE2"><strong>Reduced-Reference Image Quality Assessment Using Reorganized DCT-Based Image Representation<br>
        Lin Ma</strong>, Songnan Li, Fan Zhang, and King Ngi Ngan<br>
        IEEE Transaction on Multimedia (<strong>TMM</strong>), vol. 13, no. 4, pp. 824-829, Aug. 2011. <br>
        [<a href="welcome_files/lma_TMM_2011.pdf">Full Text</a>] </div></td>
    </tr>
    <tr class="pub_tr_2">
      <td  height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify"><strong>Practical Image Quality Metric Applied to Image Coding</strong><br>
        Fan Zhang, <strong>Lin Ma</strong>, Songnan Li, and King Ngi Ngan<br>
              IEEE Transaction on Multimedia (<strong>TMM</strong>), vol. 13, no. 4, pp. 615-624, Aug. 2011. <br>
                [<a href="welcome_files/FanZhang_TMM_2011.pdf">Full Text</a>] [<a href="http://ivp.ee.cuhk.edu.hk/projects/demo/piqm/index.html">Experimental Results</a>] </div></td>
    </tr>
    <tr class="pub_tr_2">
      <td  height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify"><strong>Adaptive Block-Size Transform Based Just-Noticeable Difference Model for Images/Videos<br>
        Lin Ma</strong>, King Ngi Ngan, Fan Zhang, and Songnan Li<br>
          Signal Processing: Image Communication (<strong>SPIC</strong>), vol. 26, no. 3, pp. 162-174, Mar. 2011. <br>
            [<a href="welcome_files/lma_SPIC_2011.pdf">Full Text</a>]</div></td>
    </tr>
    <tr class="pub_tr_2">
      <td  height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify">
        <div align="justify"><strong>Visual Horizontal Effect for Image Quality Assessment<br>
          Lin Ma</strong>, Songnan Li, and King Ngi Ngan<br>
            IEEE Signal Processing Letters (<strong>SPL</strong>), vol. 17, no. 7, pp. 627-630, Jul. 2010. <br>
            [<a href="welcome_files/lma_SPL_2010.pdf">Full Text</a>] </div>
      </div></td>
    </tr>
  </tbody>
</table>
<div class="MsoNormal" align="center" style="text-align:center">
  <hr size="2" width="100%" align="center">
</div>
<h3><span class="STYLE4">B</span><span class="STYLE2">OOKS<u><span style="font-size:12.0pt">
  <o:p></o:p>
</span></u></span></h3>
<table border="0" cellpadding="5" cellspacing="0">
  <tbody>
    <tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify"><strong>Visual Signal Quality Assessment - Quality of Experience (QoE)<br>
        </strong>Chenwei Deng, <strong> Lin Ma</strong>, Weisi Lin, and King Ngi Ngan<br>
        Springer, ISBN: 978-3-319-10367-9, 303 pages, Nov. 2014. <br>
        [<a href="http://link.springer.com/book/10.1007%2F978-3-319-10368-6">Full Text</a>] </div></td>
    </tr>
  </tbody>
</table>
<div class="MsoNormal" align="center" style="text-align:center">
  <hr size="2" width="100%" align="center">
</div>
<h3><span class="STYLE4">B</span><span class="STYLE2">OOK</span><span class="STYLE4"> C</span><span class="STYLE2">HAPTERS</span> <span class="STYLE2"><u><span style="font-size:12.0pt">
<o:p></o:p>
</span></u></span></h3>
<table border="0" cellpadding="5" cellspacing="0">
  <tbody>
    <tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"><div align="justify"><strong>Retargeted Image Quality Assessment: Current Progresses  and Future Trends</strong><br>
        <strong>Lin Ma</strong>, Chenwei Deng, Weisi Lin, King Ngi Ngan, and Long Xu<br>
        Visual Signal Quality Assessment - Quality of Experience (QoE), Springer, ISBN: 978-3-319-10367-9, pp. 213-242, Nov. 2014. <br>
        [<a href="http://link.springer.com/chapter/10.1007/978-3-319-10368-6_8">Full Text</a>] </div></td>
    </tr>
    <tr class="pub_tr_2">
      <td height="12" class="pub_td_number STYLE3">&bull;</td>
      <td height="30" class="STYLE2"> <div align="justify"><strong>Conclusions and Perspectives</strong><br>
        Chenwei Deng, Shuigen Wang, and <strong>Lin Ma</strong><br>
        Visual Signal Quality Assessment - Quality of Experience (QoE), Springer, ISBN: 978-3-319-10367-9, pp. 287-302, Nov. 2014. <br>
        [<a href="http://link.springer.com/chapter/10.1007/978-3-319-10368-6_10">Full Text</a>] </div></td>
    </tr>
  </tbody>
</table>
<div class="MsoNormal" align="center" style="text-align:center">
  <hr size="2" width="100%" align="center">
</div>
<h3>S<span class="STYLE2">ELECTED</span> P<span class="STYLE2">ROFESSIONAL </span>A<span class="STYLE2">CTIVITIES</span></h3>
<table border="0" cellpadding="5" cellspacing="0">
  <tbody>
    <tr class="pub_tr_2">
      <td width="159" class="STYLE5">Senior PC member</td>
      <td width="1269" height="30" class="STYLE2"> AAAI 2022, IJCAI 2021, IJCAI 2020, AAAI 2020, AAAI 2019 </td>
      </tr>
    <tr class="pub_tr_2">
      <td bgcolor="#FFFFFF" class="STYLE5">PC member</td>
      <td height="30" bgcolor="#FFFFFF" class="STYLE2">NeurIPS 2021, CVPR 2021, ICML 2021, ICCV 2021, ICLR 2021, AAAI 2021, ACM MM 2021, EACL 2021<br>
        NeurIPS 2020, CVPR 2020, SIGGRAPH 2020, ACL 2020, ICML 2020, ECCV 2020, EMNLP 2020, ACM MM 2020, IROS 2020, SIGIR 2020, WACV 2020<br>
        NeurIPS 2019, ICML 2019, CVPR 2019, ICCV 2019, IJCAI 2019, ACM MM 2019, BMVC 2019<br> 
      	NeurIPS 2018, ECCV 2018, CVPR 2018, ACCV 2018, SIGIR 2018, ACM MM 2018<br>
      	ICCV 2017, CVPR 2017, ECCV 2016</td>
      </tr>
    <tr class="pub_tr_2">
      <td bgcolor="#FFFFFF" class="STYLE5">Reviewer</td>
      <td height="30" bgcolor="#FFFFFF" class="STYLE2">TPAMI, IJCV, TIP, TCSVT, TMM, TCYB, TIFS</td>
      </tr>
  </tbody>
</table>
<div class="MsoNormal" align="center" style="text-align:center">
  <hr size="2" width="100%" align="center">
</div>
<h3>A<b style="mso-bidi-font-weight:
normal"><span class="STYLE2">WARDS
  <o:p></o:p>
  </span></b><span class="STYLE2" style="font-size:11.0pt;
mso-fareast-font-family:&quot;Times New Roman&quot;">
    <o:p> </o:p>
    </span>
  <span class="STYLE2">
    <o:p>&nbsp;</o:p>
  </span></h3>
<table border="0" cellpadding="5" cellspacing="0">
  <tbody>
    <tr class="pub_tr_2">
      <td height="12" class="STYLE2">Year 2014 </td>
      <td class="STYLE2"><div align="justify">Excellent new employee of Huawei</div></td>
    </tr>
    <tr class="pub_tr_2">
      <td height="12" class="STYLE2">Year 2012 </td>
      <td class="STYLE2"><div align="justify"><a href="welcome_files/HKIS_Certificate.pdf?id=208">A Finalist to the HKIS Young Scientist Award in Engineering Science</a> </div></td>
    </tr>
    <tr class="pub_tr_2">
      <td height="12" class="STYLE2">Year 2012 </td>
      <td class="STYLE2"><div align="justify"><a href="http://www.ee.cuhk.edu.hk/h_slist_ee_2011-2012.php">PCCW Foundation Scholarship </a></div></td>
    </tr>
    <tr class="pub_tr_2">
      <td height="12" class="STYLE2">Year 2011</td>
      <td class="STYLE3"><div align="justify" class="STYLE2"><a href="http://research.microsoft.com/en-us/collaboration/global/asia-pacific/talent/fellows.aspx">Microsoft Research Asia Fellowship</a></div></td>
    </tr>
    <tr class="pub_tr_2">
      <td height="12" class="STYLE2">Year 2008 </td>
      <td class="STYLE3"><div align="justify" class="STYLE2"><a href="welcome_files/lma_Best_Pape_Award.jpg">Best Paper Award</a> of Pacific-Rim Conference on Multimedia (PCM 2008)</div></td>
    </tr>
    <tr class="pub_tr_2">
      <td height="12" class="STYLE2">Year 2008</td>
      <td class="STYLE3"><div align="justify" class="STYLE2"><a href="welcome_files/lma_master_graduate.PNG">Excellent   master graduate</a> of Harbin Institute of Technology </div></td>
    </tr>
    <tr class="pub_tr_2">
      <td height="12" class="STYLE2">Year 2006-2008</td>
      <td class="STYLE3"><div align="justify" class="STYLE2">First-class postgraduate scholarship for two successive years </div></td>
    </tr>
    <tr class="pub_tr_2">
      <td width="123" height="12" class="STYLE2">Year 2004 </td>
      <td class="STYLE3"><div align="justify" class="STYLE2"><a href="welcome_files/Heqinkeji.jpg">Heqinkeji scholarship</a> </div></td>
    </tr>
    <tr class="pub_tr_2">
      <td class="STYLE2">Year 2003-2006</td>
      <td class="STYLE3"><div align="justify" class="STYLE2"><span class="STYLE2">Undergraduate student scholarships for three successive years</span></div></td>
    </tr>
  </tbody>
</table>
<hr size="2" width="100%" align="center">
<p align="center"><a href="http://www2.clustrmaps.com/counter/maps.php?url=http://www.ee.cuhk.edu.hk/~lma/" id="clustrMapsLink"><img src="http://www2.clustrmaps.com/counter/index2.php?url=http://www.ee.cuhk.edu.hk/~lma/" alt="Locations of visitors to this page" border="0" style="border:0px;" title="Locations of visitors to this page"  /></a></p>
<div class="MsoNormal" align="center" style="text-align:center">
  <p><span class="i_td_windows_footer STYLE3">Last Update: Jul. 2021. Lin Ma all rights reserved.</span></p>
</div>
</div>
</o:smarttagtype>
</o:smarttagtype></o:smarttagtype></o:smarttagtype>
<div class="MsoNormal" align="center" style="text-align:center"></div>
</body></html>